{"pt_code":"import torch\n\ndef add(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    return x + y","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef add_kernel(X_ptr, Y_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.load(X_ptr + offs, mask=mask) + tl.load(Y_ptr + offs, mask=mask)\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef add_triton(x: torch.Tensor, y: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat = x.view(-1), y.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    add_kernel[grid](x_flat, y_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "add", "triton_entrypoint": "add_triton"}
{"pt_code":"import torch\n\ndef sub(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    return x - y","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef sub_kernel(X_ptr, Y_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.load(X_ptr + offs, mask=mask) - tl.load(Y_ptr + offs, mask=mask)\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef sub_triton(x: torch.Tensor, y: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat = x.view(-1), y.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    sub_kernel[grid](x_flat, y_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "sub", "triton_entrypoint": "sub_triton"}
{"pt_code":"import torch\n\ndef mul(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    return x * y","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef mul_kernel(X_ptr, Y_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.load(X_ptr + offs, mask=mask) * tl.load(Y_ptr + offs, mask=mask)\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef mul_triton(x: torch.Tensor, y: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat = x.view(-1), y.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    mul_kernel[grid](x_flat, y_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "mul", "triton_entrypoint": "mul_triton"}
{"pt_code":"import torch\n\ndef div(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    return x / y","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef div_kernel(X_ptr, Y_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.load(X_ptr + offs, mask=mask) / tl.load(Y_ptr + offs, mask=mask)\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef div_triton(x: torch.Tensor, y: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat = x.view(-1), y.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    div_kernel[grid](x_flat, y_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "div", "triton_entrypoint": "div_triton"}
{"pt_code":"import torch\n\ndef relu(x: torch.Tensor) -> torch.Tensor:\n    return torch.relu(x)","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu_kernel(X_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    x = tl.load(X_ptr + offs, mask=mask)\n    z = tl.where(x > 0, x, tl.zeros_like(x))\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef relu_triton(x: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat = x.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    relu_kernel[grid](x_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "relu", "triton_entrypoint": "relu_triton"}
{"pt_code":"import torch\n\ndef exp(x: torch.Tensor) -> torch.Tensor:\n    return torch.exp(x)","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef exp_kernel(X_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.exp(tl.load(X_ptr + offs, mask=mask))\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef exp_triton(x: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat = x.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    exp_kernel[grid](x_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "exp", "triton_entrypoint": "exp_triton"}
{"pt_code":"import torch\n\ndef sigmoid(x: torch.Tensor) -> torch.Tensor:\n    return torch.sigmoid(x)","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef sigmoid_kernel(X_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    x = tl.load(X_ptr + offs, mask=mask)\n    z = 1 / (1 + tl.exp(-x))\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef sigmoid_triton(x: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat = x.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    sigmoid_kernel[grid](x_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "sigmoid", "triton_entrypoint": "sigmoid_triton"}
{"pt_code":"import torch\n\ndef tanh(x: torch.Tensor) -> torch.Tensor:\n    return torch.tanh(x)","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef tanh_kernel(X_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.tanh(tl.load(X_ptr + offs, mask=mask))\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef tanh_triton(x: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat = x.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    tanh_kernel[grid](x_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "tanh", "triton_entrypoint": "tanh_triton"}
{"pt_code":"import torch\n\ndef sqrt(x: torch.Tensor) -> torch.Tensor:\n    return torch.sqrt(x)","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef sqrt_kernel(X_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    z = tl.sqrt(tl.load(X_ptr + offs, mask=mask))\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef sqrt_triton(x: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat = x.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    sqrt_kernel[grid](x_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "sqrt", "triton_entrypoint": "sqrt_triton"}
{"pt_code":"import torch\n\ndef clamp(x: torch.Tensor, min_val: float, max_val: float) -> torch.Tensor:\n    return torch.clamp(x, min_val, max_val)","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef clamp_kernel(X_ptr, Z_ptr, min_val, max_val, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    x = tl.load(X_ptr + offs, mask=mask)\n    z = tl.where(x < min_val, tl.full_like(x, min_val), tl.where(x > max_val, tl.full_like(x, max_val), x))\n    tl.store(Z_ptr + offs, z, mask=mask)\n\ndef clamp_triton(x: torch.Tensor, min_val: float, max_val: float, block_size: int = 1024) -> torch.Tensor:\n    x_flat = x.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    clamp_kernel[grid](x_flat, z_flat, min_val, max_val, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "clamp", "triton_entrypoint": "clamp_triton"}
{"pt_code":"import torch\n\ndef mul_add(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n    return x * y + z","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef mul_add_kernel(X_ptr, Y_ptr, Z_ptr, W_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    a = tl.load(X_ptr + offs, mask=mask)\n    b = tl.load(Y_ptr + offs, mask=mask)\n    c = tl.load(Z_ptr + offs, mask=mask)\n    w = a * b + c\n    tl.store(W_ptr + offs, w, mask=mask)\n\ndef mul_add_triton(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat, z_flat = x.view(-1), y.view(-1), z.view(-1)\n    w_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    mul_add_kernel[grid](x_flat, y_flat, z_flat, w_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return w_flat.view_as(x)", "pt_entrypoint": "mul_add", "triton_entrypoint": "mul_add_triton"}
{"pt_code":"import torch\n\ndef add_mul(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n    return (x + y) * z","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef add_mul_kernel(X_ptr, Y_ptr, Z_ptr, W_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    s = tl.load(X_ptr + offs, mask=mask) + tl.load(Y_ptr + offs, mask=mask)\n    w = s * tl.load(Z_ptr + offs, mask=mask)\n    tl.store(W_ptr + offs, w, mask=mask)\n\ndef add_mul_triton(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat, z_flat = x.view(-1), y.view(-1), z.view(-1)\n    w_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    add_mul_kernel[grid](x_flat, y_flat, z_flat, w_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return w_flat.view_as(x)", "pt_entrypoint": "add_mul", "triton_entrypoint": "add_mul_triton"}
{"pt_code":"import torch\n\ndef relu_sum(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    return torch.relu(x) + y","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu_sum_kernel(X_ptr, Y_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    v = tl.load(X_ptr + offs, mask=mask)\n    r = tl.where(v > 0, v, tl.zeros_like(v))\n    w = r + tl.load(Y_ptr + offs, mask=mask)\n    tl.store(Z_ptr + offs, w, mask=mask)\n\ndef relu_sum_triton(x: torch.Tensor, y: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat = x.view(-1), y.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    relu_sum_kernel[grid](x_flat, y_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "relu_sum", "triton_entrypoint": "relu_sum_triton"}
{"pt_code":"import torch\n\ndef abs_add(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    return x.abs() + y","triton_code":"import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef abs_add_kernel(X_ptr, Y_ptr, Z_ptr, N, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < N\n    v = tl.load(X_ptr + offs, mask=mask)\n    a = tl.where(v >= 0, v, -v)\n    w = a + tl.load(Y_ptr + offs, mask=mask)\n    tl.store(Z_ptr + offs, w, mask=mask)\n\ndef abs_add_triton(x: torch.Tensor, y: torch.Tensor, block_size: int = 1024) -> torch.Tensor:\n    x_flat, y_flat = x.view(-1), y.view(-1)\n    z_flat = torch.empty_like(x_flat)\n    grid = lambda meta: ((x_flat.numel() + meta['BLOCK_SIZE'] - 1) // meta['BLOCK_SIZE'],)\n    abs_add_kernel[grid](x_flat, y_flat, z_flat, x_flat.numel(), BLOCK_SIZE=block_size)\n    return z_flat.view_as(x)", "pt_entrypoint": "abs_add", "triton_entrypoint": "abs_add_triton"}
