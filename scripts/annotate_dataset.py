"Reverse the jit triton kernel to pytorch code"

import openai
from rich.console import Console
from rich.pretty import pprint
from datasets import load_dataset, load_from_disk
from pydantic import BaseModel, Field

from prompts import generate_pytorch_prompt, KernelInfo, description_prompt, PytorchCodeWithTestCases

console = Console()





# console.rule("[bold blue]Generating Descriptions[/bold blue]")

client = openai.OpenAI()

## Add some description to the dataset
######################################
# dataset_name = "GPUMODE/categorized_triton_data_permissive"
# dataset = load_dataset(dataset_name, split="train")

# def generate_description(row):
#     code = row["input"]
#     response = client.beta.chat.completions.parse(
#         model="gpt-4o",
#         messages=[{"role": "user", "content": description_prompt.format(code=code)}],
#         response_format=KernelInfo,
#     )
#     return {"description": response.choices[0].message.parsed.description}



# dataset = dataset.map(generate_description, num_proc=40)
# dataset.save_to_disk("annotated_dataset")

## Generate Pytorch Code
######################################

# dataset = load_from_disk("annotated_dataset")

# def generate_pytorch_code(row):
#     code = row["input"]
#     description = row["description"]
#     response = client.beta.chat.completions.parse(
#         model="o3-mini",
#         messages=[{"role": "user", "content": generate_pytorch_prompt.format(code=code, description=description)}],
#         response_format=PytorchCodeWithTestCases,
#     )
#     return {"pytorch_code_with_test_cases": response.choices[0].message.parsed.pytorch_code_with_test_cases}


# dataset = dataset.map(generate_pytorch_code, num_proc=40)
# dataset.save_to_disk("annotated_dataset_pt")
# dataset.push_to_hub("tcapelle/annotated_dataset_o3")

## Run code
######################################

# dataset = load_from_disk("annotated_dataset_pt")

# from tools import run_python_code

# def run_code(row):
#     pytorch_code_with_test_cases = row["pytorch_code_with_test_cases"]
#     out = run_python_code(pytorch_code_with_test_cases)
#     print(f"=============== Running code ==========================")
#     print(f"status: {out['status_code']}")
#     if out['status_code'] != 0:
#         print(f"error: {out['output']}")
#     return {"test_cpu_passing": out["status_code"] == 0, "test_cpu_output": out["output"]}

# # Only run first 10 examples
# # dataset = dataset.select(range(10))
# dataset = dataset.map(run_code, num_proc=12)
# dataset.save_to_disk("annotated_dataset_pt_tested")
# dataset.push_to_hub("tcapelle/annotated_dataset_o3")


## Fix with Agent
######################################

import weave
from my_smol_agent.agent import Agent, AgentState, session
from my_smol_agent.tools import TOOLS

weave.init("mini-agent")

broken_file = "./scripts/data/airy_ai.py"

# agent = Agent(tools=TOOLS)
# agent_state = AgentState(
#     messages=[{"role": "user", 
#                "content": f"The code in this file: {broken_file} is broken. Run it, and fix the error. Save and overwrite the file."}]) 

# session(agent, agent_state)

system_prompt = """You are an expert Pytorch developer. We have a file that has tests that are failing. These tests were generated by an LLM so they may be wrong, we need you to fix the tests. 

Instructions:
- Try running the code first, to see what the error is.
- Don't change the code, only the tests.
- Fix the tests, make sure that they are fixed and the logic of the tests is preserved.
- At the last step, return only the code with the fixed tests. It should be basically the same code as the original code, but with the tests fixed.
- Don't include ```python or ``` at the beginning or end of the code.
"""

def fix_code(row):
    pytorch_code = row["pytorch_code_with_test_cases"]
    try:
        agent = Agent(system_message=system_prompt, tools=TOOLS, silent=True)
        agent_state = AgentState(
            messages=[{"role": "user", 
                    "content": f"Here is the code that needs fixing:\n#Code:\n{pytorch_code}"}]) 

        session(agent, agent_state)
    except Exception as e:
        print(f"Error: {e}")
        return {"pytorch_code_with_test_cases": pytorch_code, "test_cuda_passing": False, "fixed": False}
    return {"pytorch_code_with_test_cases": agent_state.messages[-1]["content"], "test_cuda_passing": True, "fixed": True}

dataset = load_dataset("tcapelle/annotated_dataset_o3", split="train")

dataset = dataset.filter(lambda x: not x["test_cuda_passing"])
print(f"Number of examples to fix: {len(dataset)}")
# dataset = dataset.select(range(10))

dataset = dataset.map(fix_code, num_proc=1)

