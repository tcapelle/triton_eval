"Reverse the jit triton kernel to pytorch code"

import openai
from rich.console import Console
from rich.pretty import pprint
from datasets import load_dataset, load_from_disk
from pydantic import BaseModel, Field

from prompts import generate_pytorch_prompt, KernelInfo, description_prompt, PytorchCodeWithTestCases

console = Console()





# console.rule("[bold blue]Generating Descriptions[/bold blue]")

client = openai.OpenAI()

## Add some description to the dataset
######################################
# dataset_name = "GPUMODE/categorized_triton_data_permissive"
# dataset = load_dataset(dataset_name, split="train")

# def generate_description(row):
#     code = row["input"]
#     response = client.beta.chat.completions.parse(
#         model="gpt-4o",
#         messages=[{"role": "user", "content": description_prompt.format(code=code)}],
#         response_format=KernelInfo,
#     )
#     return {"description": response.choices[0].message.parsed.description}



# dataset = dataset.map(generate_description, num_proc=40)
# dataset.save_to_disk("annotated_dataset")

## Generate Pytorch Code
######################################

# dataset = load_from_disk("annotated_dataset")

# def generate_pytorch_code(row):
#     code = row["input"]
#     description = row["description"]
#     response = client.beta.chat.completions.parse(
#         model="o3-mini",
#         messages=[{"role": "user", "content": generate_pytorch_prompt.format(code=code, description=description)}],
#         response_format=PytorchCodeWithTestCases,
#     )
#     return {"pytorch_code_with_test_cases": response.choices[0].message.parsed.pytorch_code_with_test_cases}


# dataset = dataset.map(generate_pytorch_code, num_proc=40)
# dataset.save_to_disk("annotated_dataset_pt")
# dataset.push_to_hub("tcapelle/annotated_dataset_o3")

## Run code
######################################

# dataset = load_from_disk("annotated_dataset_pt")

# from tools import run_python_code

# def run_code(row):
#     pytorch_code_with_test_cases = row["pytorch_code_with_test_cases"]
#     out = run_python_code(pytorch_code_with_test_cases)
#     print(f"=============== Running code ==========================")
#     print(f"status: {out['status_code']}")
#     if out['status_code'] != 0:
#         print(f"error: {out['output']}")
#     return {"test_cpu_passing": out["status_code"] == 0, "test_cpu_output": out["output"]}

# # Only run first 10 examples
# # dataset = dataset.select(range(10))
# dataset = dataset.map(run_code, num_proc=12)
# dataset.save_to_disk("annotated_dataset_pt_tested")
# dataset.push_to_hub("tcapelle/annotated_dataset_o3")


## Fix with Agent
######################################

import weave
from pydantic import BaseModel
from my_smol_agent.agent import Agent

system_prompt = """You are an expert Pytorch developer. We have a file that has tests that are failing. These tests were generated by an LLM so they may be wrong, we need you to fix the tests. 

# Instructions:
- Try running the code first, to see what the error is.
- Don't change the code, only the tests.
- Fix the tests, make sure that they are fixed and the logic of the tests is preserved.
- If a test cannot be fixed, remove it or create a simpler one.
- At the last step, return only the code with the fixed tests. It should be basically the same code as the original code, but with the tests fixed.


Remember to run the code one last time to make sure the tests are fixed before returning the code.
"""

weave.init("mini-agent2")

class TestedPytorchCode(BaseModel):
    code_runs: bool = Field(description="Whether the code runs or not.")
    pytorch_code: str = Field(description="The fixed Pytorch code with the tests fixed. No ```python or ``` needed, just the code.")

# # One File example
# broken_file = "./scripts/data/airy_ai.py"
# agent = Agent(system_message=system_prompt, response_format=PytorchCode)
# result = agent.run(user_prompt=f"Here is the file that needs fixing:\n#File:\n{broken_file}")
# print(result)


def fix_code(row):
    if row["test_cuda_passing"]:
        return row
    else:
        pytorch_code = row["pytorch_code_with_test_cases"]
        try:
            agent = Agent(system_message=system_prompt, silent=True, response_format=TestedPytorchCode)
            agent_response = agent.run(user_prompt=f"Here is the code that needs fixing:\n#Code:\n{pytorch_code}")
            tested_pytorch_code = agent_response.final_response
        except Exception as e:
            print(f"Error: {e}")
            return {"pytorch_code_with_test_cases_fixed": pytorch_code, "test_cuda_passing": False, "fixed": False}
        return {"pytorch_code_with_test_cases_fixed": tested_pytorch_code.pytorch_code, 
                "test_cuda_passing": tested_pytorch_code.code_runs, 
                "fixed": True}

# # iterative fix
# from rich.progress import track

# @weave.op
# def fix_test_cases(dataset):
#     fixed_rows = []
#     for row in track(dataset, description="Fixing test cases"):
#         row.update(fix_code(row))
#         fixed_rows.append(row)
#     return fixed_rows
        

dataset = load_dataset("tcapelle/annotated_dataset_o3", split="train")
# rows_list = fix_test_cases(dataset)

dataset = dataset.map(fix_code, num_proc=12)
dataset.save_to_disk("annotated_dataset_o3_fixed")
dataset.push_to_hub("tcapelle/annotated_dataset_o3")


# # from datasets import Dataset
# # new_dataset = Dataset.from_list(rows_list)
# # new_dataset.save_to_disk("annotated_dataset_o3_fixed")
# # new_dataset.push_to_hub("tcapelle/annotated_dataset_o3")