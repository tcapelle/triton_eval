{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.pretty import pprint\n",
    "from datasets import load_dataset\n",
    "from litellm import completion\n",
    "from triton_eval.utils import run_script_on_gpu, get_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"tcapelle/annotated_dataset_o3_train_pytorch_triton\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 200\n",
    "triton_code, pt_code= ds[idx][\"final_triton_code\"], ds[idx][\"final_pytorch_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to run the tests from pytorch with the generated triton kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Grab the name of the function being tested inside this code. \n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# Global device standard\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def kernel_bw_pytorch(grad_out: torch.Tensor, act_inputs: torch.Tensor, activation_grad, N: int) -> torch.Tensor:\n",
    "total_cols = act_inputs.size(1)\n",
    "if N > total_cols:\n",
    "raise ValueError(f\"N (got {N}) cannot be larger than the number of columns (got {total_cols})\")\n",
    "\n",
    "# Initialize output gradient tensor with zeros (ensuring device consistency with DEVICE)\n",
    "grad_act = torch.zeros_like(grad_out, dtype=act_inputs.dtype, device=DEVICE)\n",
    "\n",
    "# Process only the valid region (first N columns)\n",
    "valid_act_inputs = act_inputs[:, :N]\n",
    "valid_grad_out = grad_out[:, :N]\n",
    "\n",
    "# Compute the activation gradient for the valid region\n",
    "computed_grad = activation_grad(valid_act_inputs)\n",
    "\n",
    "# Element-wise multiplication with grad_out\n",
    "grad_act[:, :N] = computed_grad * valid_grad_out\n",
    "\n",
    "return grad_act\n",
    "\n",
    "########################\n",
    "\n",
    "def test_kernel_bw():\n",
    "results = {}\n",
    "\n",
    "# Define a simple activation gradient function for testing, e.g., for f(x)=x^3 then f'(x)=3*x^2\n",
    "activation_grad = lambda x: 3 * x.pow(2)\n",
    "\n",
    "# Test Case 1: Even case, where the valid region covers the entire width\n",
    "M, L = 2, 8\n",
    "N = L # valid region covers entire width\n",
    "act_inputs = torch.arange(M * L, dtype=torch.float32, device=DEVICE).reshape(M, L)\n",
    "grad_out = torch.ones((M, L), dtype=torch.float32, device=DEVICE)\n",
    "pytorch_out = kernel_bw_pytorch(grad_out, act_inputs, activation_grad, N)\n",
    "expected = 3 * act_inputs.pow(2) # expected: activation_grad(act_inputs) * grad_out\n",
    "results['even_full'] = {'pytorch': pytorch_out, 'expected': expected}\n",
    "\n",
    "# Test Case 2: Partial valid region, only first N columns are processed\n",
    "M, L = 3, 10\n",
    "N = 6\n",
    "act_inputs = torch.linspace(-5, 4, steps=M * L, dtype=torch.float32, device=DEVICE).reshape(M, L)\n",
    "grad_out = torch.full((M, L), 2.0, dtype=torch.float32, device=DEVICE)\n",
    "pytorch_out = kernel_bw_pytorch(grad_out, act_inputs, activation_grad, N)\n",
    "expected_partial = torch.zeros((M, L), dtype=torch.float32, device=DEVICE)\n",
    "expected_partial[:, :N] = activation_grad(act_inputs[:, :N]) * 2.0\n",
    "results['partial_valid'] = {'pytorch': pytorch_out, 'expected': expected_partial}\n",
    "\n",
    "# Test Case 3: Full valid region with non-trivial random inputs\n",
    "M, L = 4, 5\n",
    "N = 5\n",
    "act_inputs = torch.randn(M, L, dtype=torch.float32, device=DEVICE)\n",
    "grad_out = torch.randn(M, L, dtype=torch.float32, device=DEVICE)\n",
    "pytorch_out = kernel_bw_pytorch(grad_out, act_inputs, activation_grad, N)\n",
    "expected_full = activation_grad(act_inputs) * grad_out\n",
    "results['full_random'] = {'pytorch': pytorch_out, 'expected': expected_full}\n",
    "\n",
    "return results\n",
    "\n",
    "\n",
    "# Running tests and printing the results (only printing the test_results dictionary)\n",
    "test_results = test_kernel_bw()\n",
    "print(test_results)\n",
    "```\n",
    "\n",
    "\n",
    "You should return `kernel_bw_pytorch` as this is the function being tested.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class PytorchCode(BaseModel):\n",
    "    tested_function_name: str = Field(description=\"The name of the function being tested.\")\n",
    "\n",
    "def get_name(row, column: str=\"final_triton_code\"):\n",
    "    code = row[column]\n",
    "    if code == \"\" or code is None:\n",
    "        return {f\"{column}_entrypoint\": None}\n",
    "    result = completion(\n",
    "        model=\"gpt-4.1-mini\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\":  \"Extract the name of the function being tested from this code: \\n\\n# Code:\" + code}], \n",
    "        response_format=PytorchCode,\n",
    "        max_tokens=50)\n",
    "    out = PytorchCode.model_validate_json(result.choices[0].message.content)\n",
    "    return {f\"{column}_entrypoint\": out.tested_function_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/triton_eval/.venv/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.PytorchCode'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/workspace/triton_eval/.venv/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.PytorchCode'>: __main__.PytorchCode has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map (num_proc=10): 100%|██████████| 864/864 [00:51<00:00, 16.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(get_name, num_proc=10, fn_kwargs={\"column\": \"final_pytorch_code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/triton_eval/.venv/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.PytorchCode'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/workspace/triton_eval/.venv/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.PytorchCode'>: __main__.PytorchCode has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map (num_proc=10): 100%|██████████| 864/864 [01:00<00:00, 14.30 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(get_name, num_proc=10, fn_kwargs={\"column\": \"final_triton_code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 864/864 [00:00<00:00, 21459.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds.save_to_disk(\"ds_with_entrypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"ds_with_entrypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_triton_code': 'import torch\\nimport triton\\nimport triton.language as tl\\n\\n# Global device standard\\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n\\n@triton.jit\\ndef _matmul_kernel(A, B, C, M, N, K, **meta):\\n    \"\"\"Triton kernel for matrix multiplication using tiling.\"\"\"\\n    # Tiling sizes\\n    TILE_M = meta[\\'BLOCK_M\\']\\n    TILE_N = meta[\\'BLOCK_N\\']\\n    TILE_K = 128\\n    \\n    # Indices for output tile computed by the current program instance\\n    m = tl.program_id(0) * TILE_M + tl.arange(0, TILE_M)\\n    n = tl.program_id(1) * TILE_N + tl.arange(0, TILE_N)\\n    \\n    # Initialize the accumulator for the resultant tile\\n    acc = tl.zeros((TILE_M, TILE_N), dtype=tl.float32)\\n    \\n    # Loop over the K dimension with tiles\\n    for k in range(0, K, TILE_K):\\n        a = tl.load(A + m[:, None] * K + k, mask=[m[:, None] < M, None], other=0.0)\\n        b = tl.load(B + k * N + n, mask=[None, n < N], other=0.0)\\n        acc += tl.dot(a, b)\\n    \\n    # Store the computed tile into C\\n    tl.store(C + m[:, None] * N + n, acc, mask=[m[:, None] < M, n < N])\\n\\n\\n\\ndef matmul_triton(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\\n    \"\"\"\\n    Perform matrix multiplication using a Triton kernel that computes A @ B.\\n\\n    Parameters:\\n      A (torch.Tensor): Tensor of shape (M, K) on DEVICE.\\n      B (torch.Tensor): Tensor of shape (K, N) on DEVICE.\\n\\n    Returns:\\n      torch.Tensor: The product matrix of shape (M, N).\\n    \"\"\"\\n    # Verify dimensions\\n    if A.dim() != 2 or B.dim() != 2:\\n        raise ValueError(\\'Both A and B must be 2D tensors.\\')\\n    M, K = A.shape\\n    K2, N = B.shape\\n    if K != K2:\\n        raise ValueError(f\\'Inner dimensions must match, got A: {A.shape}, B: {B.shape}\\')\\n\\n    # Allocate the output tensor on the global DEVICE\\n    C = torch.empty((M, N), device=DEVICE, dtype=torch.float32)\\n\\n    # Define block sizes (tuning parameters)\\n    BLOCK_M = 64\\n    BLOCK_N = 64\\n    \\n    # Calculate the grid dimensions\\n    grid = ((M + BLOCK_M - 1) // BLOCK_M, (N + BLOCK_N - 1) // BLOCK_N)\\n\\n    # Launch the Triton kernel\\n    _matmul_kernel[grid](A, B, C, M, N, K, meta={\\'BLOCK_M\\': BLOCK_M, \\'BLOCK_N\\': BLOCK_N})\\n    return C\\n\\n########################\\n\\ndef test_matmul_triton():\\n    \"\"\"\\n    Test function for Triton-based matrix multiplication on DEVICE.\\n\\n    Returns:\\n      dict: Dictionary storing test results for each test case.\\n    \"\"\"\\n    results = {}\\n\\n    # Test Case 1: Small square matrices\\n    A1 = torch.tensor([[1.0, 2.0], [3.0, 4.0]], device=DEVICE)\\n    B1 = torch.tensor([[5.0, 6.0], [7.0, 8.0]], device=DEVICE)\\n    C1 = matmul_triton(A1, B1)\\n    results[\\'test_case_1\\'] = C1\\n\\n    # Test Case 2: Rectangular matrices\\n    A2 = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], device=DEVICE)  # (2, 3)\\n    B2 = torch.tensor([[7.0, 8.0], [9.0, 10.0], [11.0, 12.0]], device=DEVICE)  # (3, 2)\\n    C2 = matmul_triton(A2, B2)\\n    results[\\'test_case_2\\'] = C2\\n\\n    # Test Case 3: Larger matrices\\n    torch.manual_seed(42)\\n    A3 = torch.randn(64, 128, device=DEVICE)\\n    B3 = torch.randn(128, 32, device=DEVICE)\\n    C3 = matmul_triton(A3, B3)\\n    expected_C3 = torch.mm(A3, B3)\\n    results[\\'test_case_3\\'] = {\\n        \\'result\\': C3,\\n        \\'expected\\': expected_C3,\\n        \\'close\\': torch.allclose(C3, expected_C3)\\n    }\\n\\n    # Test Case 4: Non-divisible dimensions\\n    A4 = torch.tensor([\\n        [1.0, 2.0, 3.0], \\n        [4.0, 5.0, 6.0], \\n        [7.0, 8.0, 9.0], \\n        [10.0, 11.0, 12.0]\\n    ], device=DEVICE)  # (4, 3)\\n    B4 = torch.tensor([\\n        [2.0, 0.0], \\n        [1.0, 3.0], \\n        [0.0, 4.0]\\n    ], device=DEVICE)  # (3, 2)\\n    C4 = matmul_triton(A4, B4)\\n    results[\\'test_case_4\\'] = C4\\n\\n    # Test Case 5: Random tensors on GPU\\n    if torch.cuda.is_available():\\n        A5 = torch.randn(128, 256, device=DEVICE)\\n        B5 = torch.randn(256, 64, device=DEVICE)\\n        C5 = matmul_triton(A5, B5)\\n        expected_C5 = torch.matmul(A5, B5)\\n        results[\\'test_case_5\\'] = {\\n            \\'result\\': C5,\\n            \\'expected\\': expected_C5,\\n            \\'close\\': torch.allclose(C5, expected_C5)\\n        }\\n    else:\\n        results[\\'test_case_5\\'] = \\'CUDA not available, skipped GPU test.\\'\\n\\n    return results\\n\\n########################\\n\\n# Run tests and print only the final test_results dictionary.\\ntest_results = test_matmul_triton()\\nprint(test_results)\\n',\n",
       " 'final_pytorch_code': 'import torch\\n\\n# Global device standard\\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n\\ndef matmul_pytorch(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\\n    \"\"\"\\n    Perform matrix multiplication using pure PyTorch with torch.matmul.\\n\\n    Parameters:\\n      A (torch.Tensor): Tensor of shape (M, K) on DEVICE.\\n      B (torch.Tensor): Tensor of shape (K, N) on DEVICE.\\n\\n    Returns:\\n      torch.Tensor: The product matrix of shape (M, N).\\n    \"\"\"\\n    # Verify dimensions\\n    if A.dim() != 2 or B.dim() != 2:\\n        raise ValueError(\\'Both A and B must be 2D tensors.\\')\\n    M, K = A.shape\\n    K2, N = B.shape\\n    if K != K2:\\n        raise ValueError(f\\'Inner dimensions must match, got A: {A.shape}, B: {B.shape}\\')\\n\\n    # Perform matrix multiplication using torch.matmul\\n    return torch.matmul(A, B)\\n\\n########################\\n\\ndef test_matmul_pytorch():\\n    \"\"\"\\n    Test function for pure PyTorch matrix multiplication on DEVICE.\\n\\n    Returns:\\n      dict: Dictionary storing test results for each test case.\\n    \"\"\"\\n    results = {}\\n\\n    # Test Case 1: Small square matrices\\n    A1 = torch.tensor([[1.0, 2.0], [3.0, 4.0]], device=DEVICE)\\n    B1 = torch.tensor([[5.0, 6.0], [7.0, 8.0]], device=DEVICE)\\n    C1 = matmul_pytorch(A1, B1)\\n    results[\\'test_case_1\\'] = C1\\n\\n    # Test Case 2: Rectangular matrices\\n    A2 = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], device=DEVICE)\\n    B2 = torch.tensor([[7.0, 8.0], [9.0, 10.0], [11.0, 12.0]], device=DEVICE)\\n    C2 = matmul_pytorch(A2, B2)\\n    results[\\'test_case_2\\'] = C2\\n\\n    # Test Case 3: Larger matrices\\n    torch.manual_seed(42)\\n    A3 = torch.randn(64, 128, device=DEVICE)\\n    B3 = torch.randn(128, 32, device=DEVICE)\\n    C3 = matmul_pytorch(A3, B3)\\n    expected_C3 = torch.mm(A3, B3)\\n    results[\\'test_case_3\\'] = {\\n        \\'result\\': C3,\\n        \\'expected\\': expected_C3,\\n        \\'close\\': torch.allclose(C3, expected_C3)\\n    }\\n\\n    # Test Case 4: Non-divisible dimensions\\n    A4 = torch.tensor([\\n        [1.0, 2.0, 3.0],\\n        [4.0, 5.0, 6.0],\\n        [7.0, 8.0, 9.0],\\n        [10.0, 11.0, 12.0]\\n    ], device=DEVICE)\\n    B4 = torch.tensor([\\n        [2.0, 0.0],\\n        [1.0, 3.0],\\n        [0.0, 4.0]\\n    ], device=DEVICE)\\n    C4 = matmul_pytorch(A4, B4)\\n    results[\\'test_case_4\\'] = C4\\n\\n    # Test Case 5: Random tensors on GPU\\n    if torch.cuda.is_available():\\n        A5 = torch.randn(128, 256, device=DEVICE)\\n        B5 = torch.randn(256, 64, device=DEVICE)\\n        C5 = matmul_pytorch(A5, B5)\\n        expected_C5 = torch.matmul(A5, B5)\\n        results[\\'test_case_5\\'] = {\\n            \\'result\\': C5,\\n            \\'expected\\': expected_C5,\\n            \\'close\\': torch.allclose(C5, expected_C5)\\n        }\\n    else:\\n        results[\\'test_case_5\\'] = \\'CUDA not available, skipped GPU test.\\'\\n\\n    return results\\n\\n########################\\n\\n# Run tests and print only the final test_results dictionary.\\ntest_results = test_matmul_pytorch()\\nprint(test_results)\\n',\n",
       " 'final_pytorch_code_entrypoint': 'matmul_pytorch',\n",
       " 'final_triton_code_entrypoint': 'matmul_triton'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def grab_function_definitions(code):\n",
    "    return re.findall(r\"def\\s+(\\w+)\\s*\\(\", code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matmul_pytorch', 'test_matmul_pytorch']\n",
      "['_matmul_kernel', 'matmul_triton', 'test_matmul_triton']\n",
      "['matmul_pytorch', 'matmul_triton']\n"
     ]
    }
   ],
   "source": [
    "# grab all function definitions (any code that starts with \"def\")\n",
    "\n",
    "pt_code = ds[0][\"final_pytorch_code\"]\n",
    "triton_code = ds[0][\"final_triton_code\"]\n",
    "pt_entrypoint = ds[0][\"final_pytorch_code_entrypoint\"]\n",
    "triton_entrypoint = ds[0][\"final_triton_code_entrypoint\"]\n",
    "\n",
    "\n",
    "print(grab_function_definitions(pt_code))\n",
    "print(grab_function_definitions(triton_code))\n",
    "print([pt_entrypoint, triton_entrypoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, copy\n",
    "\n",
    "def remove_suffix(name):\n",
    "    suffixes = [\"_pytorch\", \"_triton\", \"pytorch\", \"triton\", \"_pt\", \"torch\", \"pt\", \"_python\", \"python\",\"_py\", \"py\"]\n",
    "    for suffix in suffixes:\n",
    "        if name.endswith(suffix):\n",
    "            name = name[:-len(suffix)]\n",
    "            break # Stop after removing the first matching suffix\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('matmul', 'matmul')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_suffix(\"matmul_pytorch\"), remove_suffix(\"matmul_py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000:  matmul -> ['matmul_pytorch', 'test_matmul_pytorch'] | ['_matmul_kernel', 'matmul_triton', 'test_matmul_triton'] \n",
      "001:  jagged_2_softmax -> ['jagged_2_softmax', 'gelu', 'test_jagged_2_softmax', 'test_gelu', 'run_all_tests'] | ['jagged_2_softmax_kernel', 'test_jagged_2_softmax_triton', 'test_gelu_triton', 'run_all_tests'] \n",
      "002:  fancy_function -> ['fancy_function', 'test_fancy_function'] | ['fancy_function_triton', 'test_fancy_function'] \n",
      "003:  pytorch_unpack64 -> ['pytorch_unpack64', 'test_unpack64', 'float_to_bits'] | ['unpack64_kernel_inner', 'kernel_unpack64', 'triton_unpack64', 'test_unpack64', 'float_to_bits'] \n",
      "004:  fifth_order_bwd -> ['fifth_order_bwd_pytorch', 'test_fifth_order_bwd'] | ['fifth_order_bwd_triton', 'test_fifth_order_bwd_triton'] \n",
      "005:  paged_attn -> ['paged_attn', 'test_paged_attn'] | ['paged_attn_triton', 'test_paged_attn_triton'] \n",
      "006:  gelu_glu -> ['gelu_glu_pytorch', 'test_gelu_glu_pytorch'] | ['_gelu_glu_fwd_kernel', 'gelu_glu_triton', 'test_gelu_glu_triton'] \n",
      "007:  fused_layer_norm -> ['fused_layer_norm', 'test_fused_layer_norm'] | ['triton_red_fused_native_layer_norm_0', 'triton_fused_layer_norm', 'test_triton_red_fused_native_layer_norm_0'] \n",
      "008:  attn_fwd_inner -> ['load_block', 'load_key_block', 'load_val_block', 'attn_fwd_inner', 'test_attn_fwd_inner'] | ['load_block', 'load_key_block', 'load_val_block', 'attn_fwd_inner_triton', 'test_attn_fwd_inner_triton'] \n",
      "009:  attn_bwd_dkdv -> ['attn_bwd_dkdv_py', 'test_attn_bwd_dkdv'] | ['_attn_bwd_dkdv', 'attn_bwd_dkdv_triton', 'test_attn_bwd_dkdv'] \n",
      "010:  jagged_dense_bmm -> ['jagged_dense_bmm_pytorch', 'test_jagged_dense_bmm_pytorch'] | ['jagged_dense_bmm_kernel', 'jagged_dense_bmm_triton', 'test_jagged_dense_bmm_triton'] \n",
      "011:  encode_z -> ['part1by2', '_calculate_zorder', 'encode_z', 'test_encode_z'] | ['encode_z_triton', 'test_encode_z_triton'] \n",
      "012:  sparse_attention_prefill_fwd -> ['sparse_attention_prefill_fwd', 'test_sparse_attention_prefill_fwd'] | ['_sparse_attention_prefill_fwd_kernel', 'test_sparse_attention_prefill_fwd_triton'] \n",
      "013:  jagged_softmax_backward -> ['jagged_softmax_backward_py', 'test_jagged_softmax_backward'] | ['jagged_softmax_backward_kernel', 'jagged_softmax_backward', 'test_jagged_softmax_backward'] \n",
      "014:  chunk_linear_attn_fwd -> ['chunk_linear_attn_fwd_pytorch', 'test_chunk_linear_attn_fwd'] | ['chunk_linear_attn_fwd_kernel_h', 'chunk_linear_attn_fwd_triton', 'test_chunk_linear_attn_fwd'] \n",
      "015:  layer_norm_non_affine_fw -> ['layer_norm_non_affine_fw', 'test_layer_norm_non_affine_fw_pytorch'] | ['_layer_norm_non_affine_fw_kernel', 'layer_norm_non_affine_fw', 'test_layer_norm_non_affine_fw_triton'] \n",
      "016:  kernel_bw -> ['kernel_bw_pytorch', 'test_kernel_bw'] | ['kernel_bw', 'test_kernel_bw', 'run_triton_case'] \n",
      "017:  store_1d -> ['get_1d_offset', 'get_1d_mask', 'store_1d', 'test_store_1d_pytorch'] | ['get_1d_offset', 'get_1d_mask', 'store_1d_kernel', 'store_1d_launcher', 'test_store_1d_triton'] \n",
      "018:  fancy_function -> ['fancy_function', 'test_fancy_function'] | ['fancy_function_triton', 'test_fancy_function'] \n",
      "019:  chunk_abc_fwd -> ['chunk_abc_fwd', 'test_chunk_abc_fwd_pytorch'] | ['chunk_abc_fwd_kernel_intra_K', 'test_chunk_abc_fwd_triton'] \n",
      "020:  encode_hilbert_unpadded -> ['_calculate_hilbert_distance', 'encode_hilbert_unpadded', 'test_encode_hilbert_unpadded_pytorch'] | ['_calculate_hilbert_distance', '_encode_hilbert_unpadded_kernel', 'encode_hilbert_unpadded_triton', 'test_encode_hilbert_unpadded_triton'] \n",
      "021:  custom_attention_forward -> ['custom_attention_forward_pytorch', 'test_custom_attention'] | ['custom_attention_forward_triton', 'test_custom_attention'] \n",
      "022:  relu_backward -> ['relu_backward_pytorch', 'test_relu_backward_pytorch'] | ['backward', 'relu_backward_triton', 'test_backward_triton'] \n",
      "023:  compute_block -> ['reverse_cumsum', 'compute_block', 'test_compute_block'] | ['softplus', 'compute_block', 'reverse_cumsum', 'test_compute_block'] \n",
      "024:  rotate_half -> ['rotate_half_pytorch', 'test_rotate_half'] | ['rotate_half_triton', 'test_rotate_half'] \n",
      "025:  copy_tensor -> ['copy_tensor_pytorch', 'test_copy_tensor'] | ['triton_copy_kernel', 'copy_tensor_triton', 'test_triton_copy_kernel'] \n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(ds):\n",
    "    if i > 25:\n",
    "        break\n",
    "    pt_defs = grab_function_definitions(row[\"final_pytorch_code\"])\n",
    "    triton_defs = grab_function_definitions(row[\"final_triton_code\"])\n",
    "    new_entrypoint = remove_suffix(row[\"final_pytorch_code_entrypoint\"])\n",
    "    print(f\"{i:03d}:  {new_entrypoint} -> {pt_defs} | {triton_defs} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_entrypoints(row):\n",
    "    pt_code = row[\"final_pytorch_code\"]\n",
    "    triton_code = row[\"final_triton_code\"]\n",
    "    pt_entrypoint = row[\"final_pytorch_code_entrypoint\"]\n",
    "    triton_entrypoint = row[\"final_triton_code_entrypoint\"]\n",
    "    try:\n",
    "        new_entrypoint = remove_suffix(pt_entrypoint)\n",
    "        pt_code = pt_code.replace(pt_entrypoint, new_entrypoint)\n",
    "        triton_code = triton_code.replace(triton_entrypoint, new_entrypoint)\n",
    "        return {\n",
    "            \"final_pytorch_code_renamed\": pt_code, \n",
    "            \"final_triton_code_renamed\": triton_code,\n",
    "            \"entrypoint\": new_entrypoint,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error on row {i}: {e}\")\n",
    "        return {\"final_pytorch_code_renamed\": pt_code, \"final_triton_code_renamed\": triton_code, \"entrypoint\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   0%|          | 0/864 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on row 26: 'NoneType' object has no attribute 'endswith'Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n",
      "Error on row 26: 'NoneType' object has no attribute 'endswith'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 864/864 [00:00<00:00, 5606.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(rename_entrypoints, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_pytorch\n",
      "==============================\n",
      "matmul\n"
     ]
    }
   ],
   "source": [
    "print(grab_function_definitions(ds[0][\"final_pytorch_code\"])[0])\n",
    "print(\"=\"*30)\n",
    "print(grab_function_definitions(ds[0][\"final_pytorch_code_renamed\"])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_triton_code',\n",
       " 'final_pytorch_code',\n",
       " 'final_pytorch_code_entrypoint',\n",
       " 'final_triton_code_entrypoint',\n",
       " 'final_pytorch_code_renamed',\n",
       " 'final_triton_code_renamed',\n",
       " 'entrypoint']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 47.58ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tcapelle/annotated_dataset_renamed_all/commit/aa70e436236ba8263030dcb990d15179c43c33d9', commit_message='Upload dataset', commit_description='', oid='aa70e436236ba8263030dcb990d15179c43c33d9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/tcapelle/annotated_dataset_renamed_all', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tcapelle/annotated_dataset_renamed_all'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.remove_columns([\"final_triton_code\", \"final_pytorch_code\", \"final_pytorch_code_entrypoint\", \"final_triton_code_entrypoint\"])\n",
    "ds = ds.rename_column(\"final_pytorch_code_renamed\", \"pytorch_code\")\n",
    "ds = ds.rename_column(\"final_triton_code_renamed\", \"triton_code\")\n",
    "ds.push_to_hub(\"tcapelle/annotated_dataset_renamed_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, results, file_name = run_script_on_gpu(pt_code, test_content=\"\", file_name=\"test.py\", gpu_id=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_case_1': tensor([[19., 22.],\n",
      "        [43., 50.]], device='cuda:0'), 'test_case_2': tensor([[ 58.,  64.],\n",
      "        [139., 154.]], device='cuda:0'), 'test_case_3': {'result': tensor([[  9.3524,  20.1801,   1.3200,  ..., -21.0338,   3.0357,  -8.3879],\n",
      "        [ -5.5521,   5.0191, -26.5503,  ...,  -5.4739,  -7.3350,  -0.0405],\n",
      "        [  2.6591,  -5.7370,   2.5628,  ...,  22.7629,   1.0609,  -6.0721],\n",
      "        ...,\n",
      "        [  0.7112,  11.1433,   7.8263,  ...,  -8.2718,  -5.5668,  -6.1661],\n",
      "        [ 17.1974,  -6.1684,   1.1457,  ...,  -6.9263, -12.8880,   5.2832],\n",
      "        [-10.5624,   2.1081, -10.1488,  ...,   7.4583,  -1.6897,  -1.7082]],\n",
      "       device='cuda:0'), 'expected': tensor([[  9.3524,  20.1801,   1.3200,  ..., -21.0338,   3.0357,  -8.3879],\n",
      "        [ -5.5521,   5.0191, -26.5503,  ...,  -5.4739,  -7.3350,  -0.0405],\n",
      "        [  2.6591,  -5.7370,   2.5628,  ...,  22.7629,   1.0609,  -6.0721],\n",
      "        ...,\n",
      "        [  0.7112,  11.1433,   7.8263,  ...,  -8.2718,  -5.5668,  -6.1661],\n",
      "        [ 17.1974,  -6.1684,   1.1457,  ...,  -6.9263, -12.8880,   5.2832],\n",
      "        [-10.5624,   2.1081, -10.1488,  ...,   7.4583,  -1.6897,  -1.7082]],\n",
      "       device='cuda:0'), 'close': True}, 'test_case_4': tensor([[ 4., 18.],\n",
      "        [13., 39.],\n",
      "        [22., 60.],\n",
      "        [31., 81.]], device='cuda:0'), 'test_case_5': {'result': tensor([[-20.8893,  18.6847, -25.4520,  ...,  11.5636,   0.8549,  -2.4848],\n",
      "        [  4.9682, -24.7063,   5.0134,  ...,  17.0403, -24.0015,  22.7481],\n",
      "        [ -4.9066,   7.7711,   6.0983,  ..., -12.2099,  13.7487,  -2.7126],\n",
      "        ...,\n",
      "        [-17.5489, -11.0569,   7.5630,  ...,  -6.2937, -21.6412,  19.4340],\n",
      "        [-22.7031,  -7.3231,   6.3431,  ..., -25.8886, -23.7392, -13.3596],\n",
      "        [-23.1386,  -4.5383, -27.9520,  ...,  -9.5806,   2.6319,   8.3291]],\n",
      "       device='cuda:0'), 'expected': tensor([[-20.8893,  18.6847, -25.4520,  ...,  11.5636,   0.8549,  -2.4848],\n",
      "        [  4.9682, -24.7063,   5.0134,  ...,  17.0403, -24.0015,  22.7481],\n",
      "        [ -4.9066,   7.7711,   6.0983,  ..., -12.2099,  13.7487,  -2.7126],\n",
      "        ...,\n",
      "        [-17.5489, -11.0569,   7.5630,  ...,  -6.2937, -21.6412,  19.4340],\n",
      "        [-22.7031,  -7.3231,   6.3431,  ..., -25.8886, -23.7392, -13.3596],\n",
      "        [-23.1386,  -4.5383, -27.9520,  ...,  -9.5806,   2.6319,   8.3291]],\n",
      "       device='cuda:0'), 'close': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    print(results.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_gpu, results_gpu, _ = run_script_on_gpu(pt_code, test_content=\"\", file_name=\"test.py\", gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_case_1': tensor([[19., 22.],\n",
      "        [43., 50.]], device='cuda:0'), 'test_case_2': tensor([[ 58.,  64.],\n",
      "        [139., 154.]], device='cuda:0'), 'test_case_3': {'result': tensor([[  9.3524,  20.1801,   1.3200,  ..., -21.0338,   3.0357,  -8.3879],\n",
      "        [ -5.5521,   5.0191, -26.5503,  ...,  -5.4739,  -7.3350,  -0.0405],\n",
      "        [  2.6591,  -5.7370,   2.5628,  ...,  22.7629,   1.0609,  -6.0721],\n",
      "        ...,\n",
      "        [  0.7112,  11.1433,   7.8263,  ...,  -8.2718,  -5.5668,  -6.1661],\n",
      "        [ 17.1974,  -6.1684,   1.1457,  ...,  -6.9263, -12.8880,   5.2832],\n",
      "        [-10.5624,   2.1081, -10.1488,  ...,   7.4583,  -1.6897,  -1.7082]],\n",
      "       device='cuda:0'), 'expected': tensor([[  9.3524,  20.1801,   1.3200,  ..., -21.0338,   3.0357,  -8.3879],\n",
      "        [ -5.5521,   5.0191, -26.5503,  ...,  -5.4739,  -7.3350,  -0.0405],\n",
      "        [  2.6591,  -5.7370,   2.5628,  ...,  22.7629,   1.0609,  -6.0721],\n",
      "        ...,\n",
      "        [  0.7112,  11.1433,   7.8263,  ...,  -8.2718,  -5.5668,  -6.1661],\n",
      "        [ 17.1974,  -6.1684,   1.1457,  ...,  -6.9263, -12.8880,   5.2832],\n",
      "        [-10.5624,   2.1081, -10.1488,  ...,   7.4583,  -1.6897,  -1.7082]],\n",
      "       device='cuda:0'), 'close': True}, 'test_case_4': tensor([[ 4., 18.],\n",
      "        [13., 39.],\n",
      "        [22., 60.],\n",
      "        [31., 81.]], device='cuda:0'), 'test_case_5': {'result': tensor([[-20.8893,  18.6847, -25.4520,  ...,  11.5636,   0.8549,  -2.4848],\n",
      "        [  4.9682, -24.7063,   5.0134,  ...,  17.0403, -24.0015,  22.7481],\n",
      "        [ -4.9066,   7.7711,   6.0983,  ..., -12.2099,  13.7487,  -2.7126],\n",
      "        ...,\n",
      "        [-17.5489, -11.0569,   7.5630,  ...,  -6.2937, -21.6412,  19.4340],\n",
      "        [-22.7031,  -7.3231,   6.3431,  ..., -25.8886, -23.7392, -13.3596],\n",
      "        [-23.1386,  -4.5383, -27.9520,  ...,  -9.5806,   2.6319,   8.3291]],\n",
      "       device='cuda:0'), 'expected': tensor([[-20.8893,  18.6847, -25.4520,  ...,  11.5636,   0.8549,  -2.4848],\n",
      "        [  4.9682, -24.7063,   5.0134,  ...,  17.0403, -24.0015,  22.7481],\n",
      "        [ -4.9066,   7.7711,   6.0983,  ..., -12.2099,  13.7487,  -2.7126],\n",
      "        ...,\n",
      "        [-17.5489, -11.0569,   7.5630,  ...,  -6.2937, -21.6412,  19.4340],\n",
      "        [-22.7031,  -7.3231,   6.3431,  ..., -25.8886, -23.7392, -13.3596],\n",
      "        [-23.1386,  -4.5383, -27.9520,  ...,  -9.5806,   2.6319,   8.3291]],\n",
      "       device='cuda:0'), 'close': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if success_gpu:\n",
    "    print(results_gpu.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def run_one(row, gpus=[0, 1]):\n",
    "    triton_code, pt_code = row[\"final_triton_code\"], row[\"final_pytorch_code\"]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "        future_to_file = {\n",
    "            executor.submit(run_script_on_gpu, pt_code, test_content=\"\", file_name=\"test.py\", gpu_id=gpus[0]): \"pytorch\",\n",
    "            executor.submit(run_script_on_gpu, triton_code, test_content=\"\", file_name=\"test.py\", gpu_id=gpus[1]): \"triton\"\n",
    "        }\n",
    "        for future in as_completed(future_to_file):\n",
    "            file_name = future_to_file[future]\n",
    "            success, results, _ = future.result()\n",
    "            if file_name == \"pytorch\":\n",
    "                success_pytorch = success\n",
    "                results_pytorch = results\n",
    "            else:\n",
    "                success_triton = success\n",
    "                results_triton = results\n",
    "    \n",
    "    outputs_match = results_pytorch.stdout == results_triton.stdout\n",
    "\n",
    "    return {\"pytorch_runs\": success_pytorch, \n",
    "            \"pytorch_output\": {\"stdout\": results_pytorch.stdout, \"stderr\": results_pytorch.stderr}, \n",
    "            \"triton_runs\": success_triton, \n",
    "            \"triton_output\": {\"stdout\": results_triton.stdout, \"stderr\": results_triton.stderr}, \n",
    "            \"outputs_match\": outputs_match}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 10/10 [00:21<00:00,  2.20s/ examples]\n"
     ]
    }
   ],
   "source": [
    "sample_ds = ds.select(range(10))\n",
    "sample_ds = sample_ds.map(run_one, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'final_triton_code'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'import torch\\nimport triton\\nimport triton.language as tl\\n\\n# Global device standard\\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n@triton.jit\\ndef fifth_order_bwd_triton(coord_ptr, coord_grad_ptr, sph_grad_ptr,\\n                           block_size: tl.constexpr, coord_numel: tl.constexpr,\\n                           output_numel: tl.constexpr, col_offset: tl.constexpr,\\n                           output_stride: tl.constexpr):\\n    \"\"\"\\n    Triton kernel for the backward pass.\\n    It loads coordinate values and corresponding spherical gradients (g0 to g10) and updates the gradient buffer.\\n    \"\"\"\\n    # Each program handles one block (grid dimension 0)\\n    block_id = tl.program_id(0)\\n    coord_stride = 3\\n    coord_striding = tl.arange(0, block_size) * coord_stride\\n    coord_row_offset = coord_striding + block_size * coord_stride * block_id\\n\\n    # Load coordinates x, y, z for this block\\n    x = tl.load(coord_ptr + coord_row_offset, mask=coord_row_offset &lt; coord_numel)\\n    y = tl.load(coord_ptr + coord_row_offset + 1, mask=(coord_row_offset + 1) &lt; coord_numel)\\n    z = tl.load(coord_ptr + coord_row_offset + 2, mask=(coord_row_offset + 2) &lt; coord_numel)\\n\\n    # Compute base offset for sph_grad\\n    output_striding = tl.arange(0, block_size) * output_stride\\n    output_row_offset = output_striding + block_size * output_stride * block_id + col_offset\\n\\n    # Load spherical gradients g0 to g10\\n    g0 = tl.load(sph_grad_ptr + output_row_offset, mask=output_row_offset &lt; output_numel)\\n    g1 = tl.load(sph_grad_ptr + output_row_offset + 1, mask=(output_row_offset + 1) &lt; output_numel)\\n    g2 = tl.load(sph_grad_ptr + output_row_offset + 2, mask=(output_row_offset + 2) &lt; output_numel)\\n    g3 = tl.load(sph_grad_ptr + output_row_offset + 3, mask=(output_row_offset + 3) &lt; output_numel)\\n    g4 = tl.load(sph_grad_ptr + output_row_offset + 4, mask=(output_row_offset + 4) &lt; output_numel)\\n    g5 = tl.load(sph_grad_ptr + output_row_offset + 5, mask=(output_row_offset + 5) &lt; output_numel)\\n    g6 = tl.load(sph_grad_ptr + output_row_offset + 6, mask=(output_row_offset + 6) &lt; output_numel)\\n    g7 = tl.load(sph_grad_ptr + output_row_offset + 7, mask=(output_row_offset + 7) &lt; output_numel)\\n    g8 = tl.load(sph_grad_ptr + output_row_offset + 8, mask=(output_row_offset + 8) &lt; output_numel)\\n    g9 = tl.load(sph_grad_ptr + output_row_offset + 9, mask=(output_row_offset + 9) &lt; output_numel)\\n    g10 = tl.load(sph_grad_ptr + output_row_offset + 10, mask=(output_row_offset + 10) &lt; output_numel)\\n\\n    # Define constants\\n    CONST000 = 1.60565407233314\\n    CONST001 = 3.0\\n    CONST002 = 3.21130814466628\\n    CONST003 = 1.60565407233314\\n    CONST004 = 6.42261628933256\\n    CONST005 = 6.42261628933256\\n    CONST006 = 8.67152307844476\\n    CONST007 = 8.02827036166571\\n    CONST008 = 6.9372184627558\\n    CONST009 = 11.6340690431164\\n    CONST010 = 12.8452325786651\\n    CONST011 = 6.21867148191637\\n    CONST012 = 6.21867148191637\\n    CONST014 = 12.4373429638327\\n    CONST017 = 12.8452325786651\\n    CONST018 = 13.8744369255116\\n    CONST019 = 24.8746859276655\\n    CONST020 = 24.8746859276655\\n    CONST021 = 27.7488738510232\\n    CONST024 = 29.4321253055229\\n    CONST027 = 7.35803132638072\\n    CONST029 = 46.5362761724657\\n    CONST030 = 51.3809303146605\\n    CONST031 = 51.3809303146605\\n    CONST034 = 101.955872807799\\n    CONST036 = -8.67152307844475\\n    CONST037 = 3.4686092313779\\n    CONST038 = -88.2963759165686\\n    CONST039 = -83.2466215530696\\n    CONST040 = -69.8044142586986\\n    CONST041 = -50.9779364038993\\n    CONST042 = -50.9779364038993\\n    CONST043 = -46.5362761724657\\n    CONST044 = -44.1481879582843\\n    CONST045 = -41.6233107765348\\n    CONST046 = -38.5356977359954\\n    CONST047 = -38.5356977359954\\n    CONST048 = -33.166247903554\\n    CONST049 = -33.9852909359329\\n    CONST050 = 6.42261628933257\\n    CONST051 = -33.9852909359329\\n    CONST052 = -29.4321253055229\\n    CONST053 = -27.7488738510232\\n    CONST054 = -20.8116553882674\\n    CONST055 = -19.2678488679977\\n    CONST056 = -19.2678488679977\\n    CONST057 = -16.9926454679664\\n    CONST058 = -16.9926454679664\\n    CONST059 = -13.8744369255116\\n    CONST060 = -16.583123951777\\n    CONST061 = -8.49632273398321\\n    CONST062 = -6.9372184627558\\n    CONST063 = -5.20291384706685\\n    CONST064 = -3.4686092313779\\n\\n    # Precompute powers for x, y, and z\\n    VAR06 = x * x * x * x\\n    VAR07 = x * x * x\\n    VAR08 = x * x\\n    VAR15 = y * y * y * y\\n    VAR16 = y * y * y\\n    VAR17 = y * y\\n    VAR24 = z * z * z * z\\n    VAR25 = z * z * z\\n    VAR26 = z * z\\n\\n    # Load existing gradients\\n    g_x = tl.load(coord_grad_ptr + coord_row_offset, mask=coord_row_offset &lt; coord_numel)\\n    g_y = tl.load(coord_grad_ptr + coord_row_offset + 1, mask=(coord_row_offset + 1) &lt; coord_numel)\\n    g_z = tl.load(coord_grad_ptr + coord_row_offset + 2, mask=(coord_row_offset + 2) &lt; coord_numel)\\n\\n    # Update g_x\\n    g_x = g_x + \\\\\\n          g0 * (CONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26) + \\\\\\n          g1 * y * (CONST038 * VAR08 * z - CONST052 * VAR25) + \\\\\\n          g10 * (CONST029 * VAR07 * z + CONST043 * VAR25 * x) + \\\\\\n          g2 * (CONST001 * VAR08 * (CONST059 * VAR17 + CONST064 * VAR26) + CONST006 * VAR06 - CONST045 * VAR17 * VAR26 + CONST063 * VAR24) + \\\\\\n          g3 * (CONST041 * VAR08 * y * z - CONST049 * VAR16 * z + CONST057 * VAR25 * y) + \\\\\\n          g4 * (CONST000 * VAR24 + CONST001 * VAR08 * (CONST002 * VAR26 + CONST055 * VAR17) + CONST007 * VAR06 + CONST010 * VAR15 + CONST056 * VAR17 * VAR26) + \\\\\\n          g5 * (CONST048 * VAR16 * x + y * (CONST019 * VAR07 + CONST019 * VAR26 * x)) + \\\\\\n          g6 * (CONST005 * VAR25 * x + z * (CONST004 * VAR07 + CONST046 * VAR17 * x)) + \\\\\\n          g7 * (CONST049 * VAR16 * x - CONST051 * VAR07 * y) + \\\\\\n          g8 * (CONST008 * VAR25 * x + z * (CONST039 * VAR17 * x - CONST054 * VAR07)) + \\\\\\n          g9 * y * (CONST024 * VAR07 + CONST038 * VAR26 * x)\\n\\n    # Update g_y\\n    g_y = g_y + \\\\\\n          g1 * (CONST052 * VAR07 * z - CONST052 * VAR25 * x) + \\\\\\n          g2 * (-CONST039 * VAR26 * x * y + CONST053 * VAR07 * y) + \\\\\\n          g3 * (CONST058 * VAR07 * z + x * (CONST034 * VAR17 * z + CONST057 * VAR25)) + \\\\\\n          g4 * (CONST047 * VAR07 * y + x * (CONST030 * VAR16 + CONST046 * VAR26 * y)) + \\\\\\n          g5 * (CONST001 * VAR17 * (CONST060 * VAR08 + CONST060 * VAR26) + CONST011 * VAR06 + CONST012 * VAR24 + CONST014 * VAR08 * VAR26 - CONST060 * VAR15) + \\\\\\n          g6 * (CONST046 * VAR25 * y + z * (CONST031 * VAR16 + CONST046 * VAR08 * y)) + \\\\\\n          g7 * (CONST001 * VAR17 * (CONST057 * VAR08 - CONST057 * VAR26) - CONST061 * VAR06 + CONST061 * VAR24) + \\\\\\n          g8 * (CONST021 * VAR25 * y + CONST039 * VAR08 * y * z) + \\\\\\n          g9 * (CONST027 * VAR06 + CONST027 * VAR24 + CONST044 * VAR08 * VAR26)\\n\\n    # Update g_z\\n    g_z = g_z + \\\\\\n          g0 * (CONST029 * VAR25 * x + CONST043 * VAR07 * z) + \\\\\\n          g1 * y * (-CONST038 * VAR26 * x + CONST052 * VAR07) + \\\\\\n          g10 * (CONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26) + \\\\\\n          g2 * (CONST062 * VAR07 * z + x * (-CONST039 * VAR17 * z + CONST054 * VAR25)) + \\\\\\n          g3 * (CONST058 * VAR07 * y + x * (CONST042 * VAR26 * y - CONST049 * VAR16)) + \\\\\\n          g4 * (CONST005 * VAR07 * z + x * (CONST046 * VAR17 * z + CONST050 * VAR25)) + \\\\\\n          g5 * (CONST048 * VAR16 * z + y * (CONST019 * VAR08 * z + CONST020 * VAR25)) + \\\\\\n          g6 * (CONST001 * VAR26 * (CONST002 * VAR08 + CONST056 * VAR17) + CONST003 * VAR06 + CONST007 * VAR24 + CONST017 * VAR15 + CONST056 * VAR08 * VAR17) + \\\\\\n          g7 * (-CONST049 * VAR16 * z + CONST051 * VAR25 * y) + \\\\\\n          g8 * (CONST001 * VAR26 * (CONST018 * VAR17 + CONST037 * VAR08) + CONST036 * VAR24 + CONST045 * VAR08 * VAR17 - CONST063 * VAR06) + \\\\\\n          g9 * y * (CONST024 * VAR25 + CONST038 * VAR08 * z)\\n\\n    # Store updated gradients back to memory\\n    tl.store(coord_grad_ptr + coord_row_offset, g_x, mask=coord_row_offset &lt; coord_numel)\\n    tl.store(coord_grad_ptr + coord_row_offset + 1, g_y, mask=(coord_row_offset + 1) &lt; coord_numel)\\n    tl.store(coord_grad_ptr + coord_row_offset + 2, g_z, mask=(coord_row_offset + 2) &lt; coord_numel)\\n\\n########################\\n\\ndef test_fifth_order_bwd_triton():\\n    \"\"\"\\n    Integrated tests for the Triton implementation of fifth_order_bwd.\\n    Returns a dictionary with outputs for each test case under key \\'triton\\'.\\n    \"\"\"\\n    test_results = {}\\n\\n    # ---------------- Test Case 1 ----------------\\n    # Settings: M = 4 coordinate triplets, block_size = 2, output_stride = 11, col_offset = 0\\n    block_size = 2\\n    M = 4\\n    num_blocks = (M + block_size - 1) // block_size\\n    output_stride = 11\\n    col_offset = 0\\n\\n    coord = torch.randn(3 * M, dtype=torch.float32, device=DEVICE)\\n    coord_triton = coord.clone()\\n    coord_grad_triton = torch.zeros_like(coord, device=DEVICE)\\n    sph_grad = torch.randn(num_blocks * block_size * output_stride, dtype=torch.float32, device=DEVICE)\\n\\n    grid = (num_blocks,)\\n    fifth_order_bwd_triton[grid](coord_triton, coord_grad_triton, sph_grad,\\n                                 block_size, coord_triton.numel(), sph_grad.numel(), col_offset, output_stride)\\n    test_results[\\'test_case_1\\'] = { \\'triton\\': coord_grad_triton }\\n\\n    # ---------------- Test Case 2 ----------------\\n    # Settings: M = 5 (not a multiple of block_size), block_size = 3, output_stride = 13, col_offset = 2\\n    block_size = 3\\n    M = 5\\n    num_blocks = (M + block_size - 1) // block_size\\n    output_stride = 13\\n    col_offset = 2\\n\\n    coord = torch.randn(3 * M, dtype=torch.float32, device=DEVICE)\\n    coord_triton = coord.clone()\\n    coord_grad_triton = torch.zeros_like(coord, device=DEVICE)\\n    sph_grad = torch.randn(num_blocks * block_size * output_stride, dtype=torch.float32, device=DEVICE)\\n\\n    grid = (num_blocks,)\\n    fifth_order_bwd_triton[grid](coord_triton, coord_grad_triton, sph_grad,\\n                                 block_size, coord_triton.numel(), sph_grad.numel(), col_offset, output_stride)\\n    test_results[\\'test_case_2\\'] = { \\'triton\\': coord_grad_triton }\\n\\n    # ---------------- Test Case 3 ----------------\\n    # Settings: Larger tensor, M = 16, block_size = 4, output_stride = 15, col_offset = 1\\n    block_size = 4\\n    M = 16\\n    num_blocks = (M + block_size - 1) // block_size\\n    output_stride = 15\\n    col_offset = 1\\n\\n    coord = torch.randn(3 * M, dtype=torch.float32, device=DEVICE)\\n    coord_triton = coord.clone()\\n    coord_grad_triton = torch.zeros_like(coord, device=DEVICE)\\n    sph_grad = torch.randn(num_blocks * block_size * output_stride, dtype=torch.float32, device=DEVICE)\\n\\n    grid = (num_blocks,)\\n    fifth_order_bwd_triton[grid](coord_triton, coord_grad_triton, sph_grad,\\n                                 block_size, coord_triton.numel(), sph_grad.numel(), col_offset, output_stride)\\n    test_results[\\'test_case_3\\'] = { \\'triton\\': coord_grad_triton }\\n\\n    return test_results\\n\\n# Execute tests (only one print statement)\\ntest_results = test_fifth_order_bwd_triton()\\nprint(test_results)\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'final_pytorch_code'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'import torch\\n\\n# Global device standard\\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n\\ndef fifth_order_bwd_pytorch(coord: torch.Tensor,\\n                            coord_grad: torch.Tensor,\\n                            sph_grad: torch.Tensor,\\n                            block_size: int,\\n                            col_offset: int,\\n                            output_stride: int) -&gt; torch.Tensor:\\n    \"\"\"\\n    Pure PyTorch implementation of the fifth_order_bwd backward pass.\\n    Expects a flattened coordinate tensor (with groups [x, y, z]), a gradient buffer,\\n    and a spherical gradient tensor holding 11 gradient values per coordinate in a strided format.\\n    \"\"\"\\n    # Define constants (identical to Triton version)\\n    CONST000 = 1.60565407233314\\n    CONST001 = 3.0\\n    CONST002 = 3.21130814466628\\n    CONST003 = 1.60565407233314\\n    CONST004 = 6.42261628933256\\n    CONST005 = 6.42261628933256\\n    CONST006 = 8.67152307844476\\n    CONST007 = 8.02827036166571\\n    CONST008 = 6.9372184627558\\n    CONST009 = 11.6340690431164\\n    CONST010 = 12.8452325786651\\n    CONST011 = 6.21867148191637\\n    CONST012 = 6.21867148191637\\n    CONST014 = 12.4373429638327\\n    CONST017 = 12.8452325786651\\n    CONST018 = 13.8744369255116\\n    CONST019 = 24.8746859276655\\n    CONST020 = 24.8746859276655\\n    CONST021 = 27.7488738510232\\n    CONST024 = 29.4321253055229\\n    CONST027 = 7.35803132638072\\n    CONST029 = 46.5362761724657\\n    CONST030 = 51.3809303146605\\n    CONST031 = 51.3809303146605\\n    CONST034 = 101.955872807799\\n    CONST036 = -8.67152307844475\\n    CONST037 = 3.4686092313779\\n    CONST038 = -88.2963759165686\\n    CONST039 = -83.2466215530696\\n    CONST040 = -69.8044142586986\\n    CONST041 = -50.9779364038993\\n    CONST042 = -50.9779364038993\\n    CONST043 = -46.5362761724657\\n    CONST044 = -44.1481879582843\\n    CONST045 = -41.6233107765348\\n    CONST046 = -38.5356977359954\\n    CONST047 = -38.5356977359954\\n    CONST048 = -33.166247903554\\n    CONST049 = -33.9852909359329\\n    CONST050 = 6.42261628933257\\n    CONST051 = -33.9852909359329\\n    CONST052 = -29.4321253055229\\n    CONST053 = -27.7488738510232\\n    CONST054 = -20.8116553882674\\n    CONST055 = -19.2678488679977\\n    CONST056 = -19.2678488679977\\n    CONST057 = -16.9926454679664\\n    CONST058 = -16.9926454679664\\n    CONST059 = -13.8744369255116\\n    CONST060 = -16.583123951777\\n    CONST061 = -8.49632273398321\\n    CONST062 = -6.9372184627558\\n    CONST063 = -5.20291384706685\\n    CONST064 = -3.4686092313779\\n\\n    # Number of coordinate triplets\\n    M = coord.numel() // 3\\n    num_blocks = (M + block_size - 1) // block_size\\n\\n    # Process each block and each coordinate triplet\\n    for b in range(num_blocks):\\n        for i in range(block_size):\\n            m = b * block_size + i\\n            if m &gt;= M:\\n                break\\n            idx = m * 3\\n            # Load coordinates for the m-th triplet\\n            x = coord[idx]\\n            y = coord[idx + 1]\\n            z = coord[idx + 2]\\n\\n            # Compute base index for sph_grad for this coordinate\\n            base = b * block_size * output_stride + i * output_stride + col_offset\\n            if base + 10 &gt;= sph_grad.numel():\\n                continue\\n            # Load spherical gradients g0 to g10\\n            g0  = sph_grad[base + 0]\\n            g1  = sph_grad[base + 1]\\n            g2  = sph_grad[base + 2]\\n            g3  = sph_grad[base + 3]\\n            g4  = sph_grad[base + 4]\\n            g5  = sph_grad[base + 5]\\n            g6  = sph_grad[base + 6]\\n            g7  = sph_grad[base + 7]\\n            g8  = sph_grad[base + 8]\\n            g9  = sph_grad[base + 9]\\n            g10 = sph_grad[base + 10]\\n\\n            # Precompute polynomial terms\\n            VAR06 = x ** 4\\n            VAR07 = x ** 3\\n            VAR08 = x ** 2\\n            VAR15 = y ** 4\\n            VAR16 = y ** 3\\n            VAR17 = y ** 2\\n            VAR24 = z ** 4\\n            VAR25 = z ** 3\\n            VAR26 = z ** 2\\n\\n            # Load current gradients\\n            g_x = coord_grad[idx]\\n            g_y = coord_grad[idx + 1]\\n            g_z = coord_grad[idx + 2]\\n\\n            # Update gradients identically as in the Triton kernel\\n            g_x = g_x + \\\\\\n                  g0 * (CONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26) + \\\\\\n                  g1 * y * (CONST038 * VAR08 * z - CONST052 * VAR25) + \\\\\\n                  g10 * (CONST029 * VAR07 * z + CONST043 * VAR25 * x) + \\\\\\n                  g2 * (CONST001 * VAR08 * (CONST059 * VAR17 + CONST064 * VAR26) + CONST006 * VAR06 - CONST045 * VAR17 * VAR26 + CONST063 * VAR24) + \\\\\\n                  g3 * (CONST041 * VAR08 * y * z - CONST049 * VAR16 * z + CONST057 * VAR25 * y) + \\\\\\n                  g4 * (CONST000 * VAR24 + CONST001 * VAR08 * (CONST002 * VAR26 + CONST055 * VAR17) + CONST007 * VAR06 + CONST010 * VAR15 + CONST056 * VAR17 * VAR26) + \\\\\\n                  g5 * (CONST048 * VAR16 * x + y * (CONST019 * VAR07 + CONST019 * VAR26 * x)) + \\\\\\n                  g6 * (CONST005 * VAR25 * x + z * (CONST004 * VAR07 + CONST046 * VAR17 * x)) + \\\\\\n                  g7 * (CONST049 * VAR16 * x - CONST051 * VAR07 * y) + \\\\\\n                  g8 * (CONST008 * VAR25 * x + z * (CONST039 * VAR17 * x - CONST054 * VAR07)) + \\\\\\n                  g9 * y * (CONST024 * VAR07 + CONST038 * VAR26 * x)\\n\\n            g_y = g_y + \\\\\\n                  g1 * (CONST052 * VAR07 * z - CONST052 * VAR25 * x) + \\\\\\n                  g2 * (-CONST039 * VAR26 * x * y + CONST053 * VAR07 * y) + \\\\\\n                  g3 * (CONST058 * VAR07 * z + x * (CONST034 * VAR17 * z + CONST057 * VAR25)) + \\\\\\n                  g4 * (CONST047 * VAR07 * y + x * (CONST030 * VAR16 + CONST046 * VAR26 * y)) + \\\\\\n                  g5 * (CONST001 * VAR17 * (CONST060 * VAR08 + CONST060 * VAR26) + CONST011 * VAR06 + CONST012 * VAR24 + CONST014 * VAR08 * VAR26 - CONST060 * VAR15) + \\\\\\n                  g6 * (CONST046 * VAR25 * y + z * (CONST031 * VAR16 + CONST046 * VAR08 * y)) + \\\\\\n                  g7 * (CONST001 * VAR17 * (CONST057 * VAR08 - CONST057 * VAR26) - CONST061 * VAR06 + CONST061 * VAR24) + \\\\\\n                  g8 * (CONST021 * VAR25 * y + CONST039 * VAR08 * y * z) + \\\\\\n                  g9 * (CONST027 * VAR06 + CONST027 * VAR24 + CONST044 * VAR08 * VAR26)\\n\\n            g_z = g_z + \\\\\\n                  g0 * (CONST029 * VAR25 * x + CONST043 * VAR07 * z) + \\\\\\n                  g1 * y * (-CONST038 * VAR26 * x + CONST052 * VAR07) + \\\\\\n                  g10 * (CONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26) + \\\\\\n                  g2 * (CONST062 * VAR07 * z + x * (-CONST039 * VAR17 * z + CONST054 * VAR25)) + \\\\\\n                  g3 * (CONST058 * VAR07 * y + x * (CONST042 * VAR26 * y - CONST049 * VAR16)) + \\\\\\n                  g4 * (CONST005 * VAR07 * z + x * (CONST046 * VAR17 * z + CONST050 * VAR25)) + \\\\\\n                  g5 * (CONST048 * VAR16 * z + y * (CONST019 * VAR08 * z + CONST020 * VAR25)) + \\\\\\n                  g6 * (CONST001 * VAR26 * (CONST002 * VAR08 + CONST056 * VAR17) + CONST003 * VAR06 + CONST007 * VAR24 + CONST017 * VAR15 + CONST056 * VAR08 * VAR17) + \\\\\\n                  g7 * (-CONST049 * VAR16 * z + CONST051 * VAR25 * y) + \\\\\\n                  g8 * (CONST001 * VAR26 * (CONST018 * VAR17 + CONST037 * VAR08) + CONST036 * VAR24 + CONST045 * VAR08 * VAR17 - CONST063 * VAR06) + \\\\\\n                  g9 * y * (CONST024 * VAR25 + CONST038 * VAR08 * z)\\n\\n            # Store updated gradients\\n            coord_grad[idx] = g_x\\n            coord_grad[idx + 1] = g_y\\n            coord_grad[idx + 2] = g_z\\n    return coord_grad\\n\\n\\n########################\\n\\ndef test_fifth_order_bwd():\\n    \"\"\"\\n    Run integrated tests for the PyTorch implementation.\\n    Returns a dictionary with outputs from each test case under key \\'pytorch\\'.\\n    \"\"\"\\n    results = {}\\n\\n    # ---------------- Test Case 1 ----------------\\n    # Settings: M = 4 coordinate triplets, block_size = 2, output_stride = 11, col_offset = 0\\n    block_size = 2\\n    M = 4\\n    num_blocks = (M + block_size - 1) // block_size\\n    output_stride = 11\\n    col_offset = 0\\n\\n    coord = torch.randn(3 * M, dtype=torch.float32, device=DEVICE)\\n    coord_pytorch = coord.clone()\\n    coord_grad_pytorch = torch.zeros_like(coord, device=DEVICE)\\n    sph_grad = torch.randn(num_blocks * block_size * output_stride, dtype=torch.float32, device=DEVICE)\\n\\n    updated_grad_pytorch = fifth_order_bwd_pytorch(coord_pytorch, coord_grad_pytorch.clone(), sph_grad,\\n                                                     block_size, col_offset, output_stride)\\n    results[\\'test_case_1\\'] = { \\'pytorch\\': updated_grad_pytorch }\\n\\n    # ---------------- Test Case 2 ----------------\\n    # Settings: M = 5 (not a multiple of block_size), block_size = 3, output_stride = 13, col_offset = 2\\n    block_size = 3\\n    M = 5\\n    num_blocks = (M + block_size - 1) // block_size\\n    output_stride = 13\\n    col_offset = 2\\n\\n    coord = torch.randn(3 * M, dtype=torch.float32, device=DEVICE)\\n    coord_pytorch = coord.clone()\\n    coord_grad_pytorch = torch.zeros_like(coord, device=DEVICE)\\n    sph_grad = torch.randn(num_blocks * block_size * output_stride, dtype=torch.float32, device=DEVICE)\\n\\n    updated_grad_pytorch = fifth_order_bwd_pytorch(coord_pytorch, coord_grad_pytorch.clone(), sph_grad,\\n                                                     block_size, col_offset, output_stride)\\n    results[\\'test_case_2\\'] = { \\'pytorch\\': updated_grad_pytorch }\\n\\n    # ---------------- Test Case 3 ----------------\\n    # Settings: Larger tensor, M = 16, block_size = 4, output_stride = 15, col_offset = 1\\n    block_size = 4\\n    M = 16\\n    num_blocks = (M + block_size - 1) // block_size\\n    output_stride = 15\\n    col_offset = 1\\n\\n    coord = torch.randn(3 * M, dtype=torch.float32, device=DEVICE)\\n    coord_pytorch = coord.clone()\\n    coord_grad_pytorch = torch.zeros_like(coord, device=DEVICE)\\n    sph_grad = torch.randn(num_blocks * block_size * output_stride, dtype=torch.float32, device=DEVICE)\\n\\n    updated_grad_pytorch = fifth_order_bwd_pytorch(coord_pytorch, coord_grad_pytorch.clone(), sph_grad,\\n                                                     block_size, col_offset, output_stride)\\n    results[\\'test_case_3\\'] = { \\'pytorch\\': updated_grad_pytorch }\\n\\n    return results\\n\\n# Execute tests (only one print statement)\\ntest_results = test_fifth_order_bwd()\\nprint(test_results)\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pytorch_runs'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pytorch_output'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'stderr'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Traceback (most recent call last):\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 35, in wrapper\\n    return fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 1187, in arange\\n    return semantic.arange(start, end, _builder)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/semantic.py\", line 613, in arange\\n    raise ValueError(\"arange\\'s range must be a power of 2\")\\nValueError: arange\\'s range must be a power of 2\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 228, in &lt;module&gt;\\n    test_results = test_fifth_order_bwd_triton()\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 203, in test_fifth_order_bwd_triton\\n    fifth_order_bwd_triton[grid](coord_triton, coord_grad_triton, sph_grad,\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 330, in &lt;lambda&gt;\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 623, in run\\n    kernel = self.compile(\\n             ^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 273, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 100, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\ntriton.compiler.errors.CompilationError: at 12:21:\\ndef fifth_order_bwd_triton(coord_ptr, coord_grad_ptr, sph_grad_ptr,\\n                           block_size: tl.constexpr, coord_numel: tl.constexpr,\\n                           output_numel: tl.constexpr, col_offset: tl.constexpr,\\n                           output_stride: tl.constexpr):\\n    \"\"\"\\n    Triton kernel for the backward pass.\\n    It loads coordinate values and corresponding spherical gradients (g0 to g10) and updates the gradient buffer.\\n    \"\"\"\\n    # Each program handles one block (grid dimension 0)\\n    block_id = tl.program_id(0)\\n    coord_stride = 3\\n    coord_striding = tl.arange(0, block_size) * coord_stride\\n                     ^\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'stdout'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'triton_runs'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'triton_output'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'stderr'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Traceback (most recent call last):\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 35, in wrapper\\n    return fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 1187, in arange\\n    return semantic.arange(start, end, _builder)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/semantic.py\", line 613, in arange\\n    raise ValueError(\"arange\\'s range must be a power of 2\")\\nValueError: arange\\'s range must be a power of 2\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 228, in &lt;module&gt;\\n    test_results = test_fifth_order_bwd_triton()\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 203, in test_fifth_order_bwd_triton\\n    fifth_order_bwd_triton[grid](coord_triton, coord_grad_triton, sph_grad,\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 330, in &lt;lambda&gt;\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 623, in run\\n    kernel = self.compile(\\n             ^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 273, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 100, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\ntriton.compiler.errors.CompilationError: at 12:21:\\ndef fifth_order_bwd_triton(coord_ptr, coord_grad_ptr, sph_grad_ptr,\\n                           block_size: tl.constexpr, coord_numel: tl.constexpr,\\n                           output_numel: tl.constexpr, col_offset: tl.constexpr,\\n                           output_stride: tl.constexpr):\\n    \"\"\"\\n    Triton kernel for the backward pass.\\n    It loads coordinate values and corresponding spherical gradients (g0 to g10) and updates the gradient buffer.\\n    \"\"\"\\n    # Each program handles one block (grid dimension 0)\\n    block_id = tl.program_id(0)\\n    coord_stride = 3\\n    coord_striding = tl.arange(0, block_size) * coord_stride\\n                     ^\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'stdout'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'outputs_match'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'final_triton_code'\u001b[0m: \u001b[32m'import torch\\nimport triton\\nimport triton.language as tl\\n\\n# Global device standard\\nDEVICE = torch.device\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"cuda\" if torch.cuda.is_available\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m else \"cpu\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n@triton.jit\\ndef fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_ptr, coord_grad_ptr, sph_grad_ptr,\\n                           block_size: tl.constexpr, coord_numel: tl.constexpr,\\n                           output_numel: tl.constexpr, col_offset: tl.constexpr,\\n                           output_stride: tl.constexpr\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    \"\"\"\\n    Triton kernel for the backward pass.\\n    It loads coordinate values and corresponding spherical gradients \u001b[0m\u001b[32m(\u001b[0m\u001b[32mg0 to g10\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and updates the gradient buffer.\\n    \"\"\"\\n    # Each program handles one block \u001b[0m\u001b[32m(\u001b[0m\u001b[32mgrid dimension 0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    block_id = tl.program_id\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_stride = 3\\n    coord_striding = tl.arange\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0, block_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m * coord_stride\\n    coord_row_offset = coord_striding + block_size * coord_stride * block_id\\n\\n    # Load coordinates x, y, z for this block\\n    x = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_ptr + coord_row_offset, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcoord_row_offset\u001b[0m\u001b[32m \u001b[0m\u001b[32m<\u001b[0m\u001b[32m coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    y = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_ptr + coord_row_offset + 1, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_row_offset + 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    z = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_ptr + coord_row_offset + 2, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_row_offset + 2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    # Compute base offset for sph_grad\\n    output_striding = tl.arange\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0, block_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m * output_stride\\n    output_row_offset = output_striding + block_size * output_stride * block_id + col_offset\\n\\n    # Load spherical gradients g0 to g10\\n    g0 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32moutput_row_offset\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g1 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 1, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g2 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 2, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g3 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 3, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g4 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 4, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g5 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 5, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g6 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 6, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 6\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g7 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 7, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 7\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g8 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 8, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 8\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g9 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 9, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 9\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g10 = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32msph_grad_ptr + output_row_offset + 10, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32moutput_row_offset + 10\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < output_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    # Define constants\\n    CONST000 = 1.60565407233314\\n    CONST001 = 3.0\\n    CONST002 = 3.21130814466628\\n    CONST003 = 1.60565407233314\\n    CONST004 = 6.42261628933256\\n    CONST005 = 6.42261628933256\\n    CONST006 = 8.67152307844476\\n    CONST007 = 8.02827036166571\\n    CONST008 = 6.9372184627558\\n    CONST009 = 11.6340690431164\\n    CONST010 = 12.8452325786651\\n    CONST011 = 6.21867148191637\\n    CONST012 = 6.21867148191637\\n    CONST014 = 12.4373429638327\\n    CONST017 = 12.8452325786651\\n    CONST018 = 13.8744369255116\\n    CONST019 = 24.8746859276655\\n    CONST020 = 24.8746859276655\\n    CONST021 = 27.7488738510232\\n    CONST024 = 29.4321253055229\\n    CONST027 = 7.35803132638072\\n    CONST029 = 46.5362761724657\\n    CONST030 = 51.3809303146605\\n    CONST031 = 51.3809303146605\\n    CONST034 = 101.955872807799\\n    CONST036 = -8.67152307844475\\n    CONST037 = 3.4686092313779\\n    CONST038 = -88.2963759165686\\n    CONST039 = -83.2466215530696\\n    CONST040 = -69.8044142586986\\n    CONST041 = -50.9779364038993\\n    CONST042 = -50.9779364038993\\n    CONST043 = -46.5362761724657\\n    CONST044 = -44.1481879582843\\n    CONST045 = -41.6233107765348\\n    CONST046 = -38.5356977359954\\n    CONST047 = -38.5356977359954\\n    CONST048 = -33.166247903554\\n    CONST049 = -33.9852909359329\\n    CONST050 = 6.42261628933257\\n    CONST051 = -33.9852909359329\\n    CONST052 = -29.4321253055229\\n    CONST053 = -27.7488738510232\\n    CONST054 = -20.8116553882674\\n    CONST055 = -19.2678488679977\\n    CONST056 = -19.2678488679977\\n    CONST057 = -16.9926454679664\\n    CONST058 = -16.9926454679664\\n    CONST059 = -13.8744369255116\\n    CONST060 = -16.583123951777\\n    CONST061 = -8.49632273398321\\n    CONST062 = -6.9372184627558\\n    CONST063 = -5.20291384706685\\n    CONST064 = -3.4686092313779\\n\\n    # Precompute powers for x, y, and z\\n    VAR06 = x * x * x * x\\n    VAR07 = x * x * x\\n    VAR08 = x * x\\n    VAR15 = y * y * y * y\\n    VAR16 = y * y * y\\n    VAR17 = y * y\\n    VAR24 = z * z * z * z\\n    VAR25 = z * z * z\\n    VAR26 = z * z\\n\\n    # Load existing gradients\\n    g_x = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_grad_ptr + coord_row_offset, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcoord_row_offset\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g_y = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_grad_ptr + coord_row_offset + 1, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_row_offset + 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    g_z = tl.load\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_grad_ptr + coord_row_offset + 2, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_row_offset + 2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    # Update g_x\\n    g_x = g_x + \\\\\\n          g0 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g1 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST038 * VAR08 * z - CONST052 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g10 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST029 * VAR07 * z + CONST043 * VAR25 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g2 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR08 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST059 * VAR17 + CONST064 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST006 * VAR06 - CONST045 * VAR17 * VAR26 + CONST063 * VAR24\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g3 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST041 * VAR08 * y * z - CONST049 * VAR16 * z + CONST057 * VAR25 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g4 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST000 * VAR24 + CONST001 * VAR08 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST002 * VAR26 + CONST055 * VAR17\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST007 * VAR06 + CONST010 * VAR15 + CONST056 * VAR17 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g5 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST048 * VAR16 * x + y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST019 * VAR07 + CONST019 * VAR26 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g6 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST005 * VAR25 * x + z * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST004 * VAR07 + CONST046 * VAR17 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g7 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST049 * VAR16 * x - CONST051 * VAR07 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g8 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST008 * VAR25 * x + z * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST039 * VAR17 * x - CONST054 * VAR07\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g9 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST024 * VAR07 + CONST038 * VAR26 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    # Update g_y\\n    g_y = g_y + \\\\\\n          g1 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST052 * VAR07 * z - CONST052 * VAR25 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g2 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST039 * VAR26 * x * y + CONST053 * VAR07 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g3 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST058 * VAR07 * z + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST034 * VAR17 * z + CONST057 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g4 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST047 * VAR07 * y + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST030 * VAR16 + CONST046 * VAR26 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g5 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR17 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST060 * VAR08 + CONST060 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST011 * VAR06 + CONST012 * VAR24 + CONST014 * VAR08 * VAR26 - CONST060 * VAR15\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g6 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST046 * VAR25 * y + z * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST031 * VAR16 + CONST046 * VAR08 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g7 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR17 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST057 * VAR08 - CONST057 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m - CONST061 * VAR06 + CONST061 * VAR24\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g8 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST021 * VAR25 * y + CONST039 * VAR08 * y * z\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g9 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST027 * VAR06 + CONST027 * VAR24 + CONST044 * VAR08 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    # Update g_z\\n    g_z = g_z + \\\\\\n          g0 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST029 * VAR25 * x + CONST043 * VAR07 * z\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g1 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST038 * VAR26 * x + CONST052 * VAR07\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g10 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g2 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST062 * VAR07 * z + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST039 * VAR17 * z + CONST054 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g3 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST058 * VAR07 * y + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST042 * VAR26 * y - CONST049 * VAR16\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g4 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST005 * VAR07 * z + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST046 * VAR17 * z + CONST050 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g5 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST048 * VAR16 * z + y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST019 * VAR08 * z + CONST020 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g6 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR26 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST002 * VAR08 + CONST056 * VAR17\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST003 * VAR06 + CONST007 * VAR24 + CONST017 * VAR15 + CONST056 * VAR08 * VAR17\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g7 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST049 * VAR16 * z + CONST051 * VAR25 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g8 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR26 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST018 * VAR17 + CONST037 * VAR08\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST036 * VAR24 + CONST045 * VAR08 * VAR17 - CONST063 * VAR06\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n          g9 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST024 * VAR25 + CONST038 * VAR08 * z\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    # Store updated gradients back to memory\\n    tl.store\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_grad_ptr + coord_row_offset, g_x, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcoord_row_offset\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    tl.store\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_grad_ptr + coord_row_offset + 1, g_y, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_row_offset + 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    tl.store\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_grad_ptr + coord_row_offset + 2, g_z, \u001b[0m\u001b[32mmask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_row_offset + 2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m < coord_numel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n########################\\n\\ndef test_fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    \"\"\"\\n    Integrated tests for the Triton implementation of fifth_order_bwd.\\n    Returns a dictionary with outputs for each test case under key \\'triton\\'.\\n    \"\"\"\\n    test_results = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    # ---------------- Test Case 1 ----------------\\n    # Settings: M = 4 coordinate triplets, block_size = 2, output_stride = 11, col_offset = 0\\n    block_size = 2\\n    M = 4\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n    output_stride = 11\\n    col_offset = 0\\n\\n    coord = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3 * M, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_triton = coord.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_grad_triton = torch.zeros_like\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    sph_grad = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks * block_size * output_stride, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    grid = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks,\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    fifth_order_bwd_triton\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_triton, coord_grad_triton, sph_grad,\\n                                 block_size, coord_triton.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, sph_grad.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, col_offset, output_stride\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    test_results\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\'test_case_1\\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \\'triton\\': coord_grad_triton \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    # ---------------- Test Case 2 ----------------\\n    # Settings: M = 5 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mnot a multiple of block_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, block_size = 3, output_stride = 13, col_offset = 2\\n    block_size = 3\\n    M = 5\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n    output_stride = 13\\n    col_offset = 2\\n\\n    coord = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3 * M, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_triton = coord.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_grad_triton = torch.zeros_like\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    sph_grad = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks * block_size * output_stride, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    grid = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks,\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    fifth_order_bwd_triton\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_triton, coord_grad_triton, sph_grad,\\n                                 block_size, coord_triton.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, sph_grad.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, col_offset, output_stride\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    test_results\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\'test_case_2\\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \\'triton\\': coord_grad_triton \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    # ---------------- Test Case 3 ----------------\\n    # Settings: Larger tensor, M = 16, block_size = 4, output_stride = 15, col_offset = 1\\n    block_size = 4\\n    M = 16\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n    output_stride = 15\\n    col_offset = 1\\n\\n    coord = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3 * M, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_triton = coord.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_grad_triton = torch.zeros_like\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    sph_grad = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks * block_size * output_stride, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    grid = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks,\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    fifth_order_bwd_triton\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_triton, coord_grad_triton, sph_grad,\\n                                 block_size, coord_triton.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, sph_grad.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, col_offset, output_stride\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    test_results\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\'test_case_3\\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \\'triton\\': coord_grad_triton \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    return test_results\\n\\n# Execute tests \u001b[0m\u001b[32m(\u001b[0m\u001b[32monly one print statement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\ntest_results = test_fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtest_results\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'final_pytorch_code'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'import torch\\n\\n# Global device standard\\nDEVICE = torch.device\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"cuda\" if torch.cuda.is_available\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m else \"cpu\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n\\ndef fifth_order_bwd_pytorch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord: torch.Tensor,\\n                            coord_grad: torch.Tensor,\\n                            sph_grad: torch.Tensor,\\n                            block_size: int,\\n                            col_offset: int,\\n                            output_stride: int\u001b[0m\u001b[32m)\u001b[0m\u001b[32m -> torch.Tensor:\\n    \"\"\"\\n    Pure PyTorch implementation of the fifth_order_bwd backward pass.\\n    Expects a flattened coordinate tensor \u001b[0m\u001b[32m(\u001b[0m\u001b[32mwith groups \u001b[0m\u001b[32m[\u001b[0m\u001b[32mx, y, z\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, a gradient buffer,\\n    and a spherical gradient tensor holding 11 gradient values per coordinate in a strided format.\\n    \"\"\"\\n    # Define constants \u001b[0m\u001b[32m(\u001b[0m\u001b[32midentical to Triton version\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    CONST000 = 1.60565407233314\\n    CONST001 = 3.0\\n    CONST002 = 3.21130814466628\\n    CONST003 = 1.60565407233314\\n    CONST004 = 6.42261628933256\\n    CONST005 = 6.42261628933256\\n    CONST006 = 8.67152307844476\\n    CONST007 = 8.02827036166571\\n    CONST008 = 6.9372184627558\\n    CONST009 = 11.6340690431164\\n    CONST010 = 12.8452325786651\\n    CONST011 = 6.21867148191637\\n    CONST012 = 6.21867148191637\\n    CONST014 = 12.4373429638327\\n    CONST017 = 12.8452325786651\\n    CONST018 = 13.8744369255116\\n    CONST019 = 24.8746859276655\\n    CONST020 = 24.8746859276655\\n    CONST021 = 27.7488738510232\\n    CONST024 = 29.4321253055229\\n    CONST027 = 7.35803132638072\\n    CONST029 = 46.5362761724657\\n    CONST030 = 51.3809303146605\\n    CONST031 = 51.3809303146605\\n    CONST034 = 101.955872807799\\n    CONST036 = -8.67152307844475\\n    CONST037 = 3.4686092313779\\n    CONST038 = -88.2963759165686\\n    CONST039 = -83.2466215530696\\n    CONST040 = -69.8044142586986\\n    CONST041 = -50.9779364038993\\n    CONST042 = -50.9779364038993\\n    CONST043 = -46.5362761724657\\n    CONST044 = -44.1481879582843\\n    CONST045 = -41.6233107765348\\n    CONST046 = -38.5356977359954\\n    CONST047 = -38.5356977359954\\n    CONST048 = -33.166247903554\\n    CONST049 = -33.9852909359329\\n    CONST050 = 6.42261628933257\\n    CONST051 = -33.9852909359329\\n    CONST052 = -29.4321253055229\\n    CONST053 = -27.7488738510232\\n    CONST054 = -20.8116553882674\\n    CONST055 = -19.2678488679977\\n    CONST056 = -19.2678488679977\\n    CONST057 = -16.9926454679664\\n    CONST058 = -16.9926454679664\\n    CONST059 = -13.8744369255116\\n    CONST060 = -16.583123951777\\n    CONST061 = -8.49632273398321\\n    CONST062 = -6.9372184627558\\n    CONST063 = -5.20291384706685\\n    CONST064 = -3.4686092313779\\n\\n    # Number of coordinate triplets\\n    M = coord.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // 3\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n\\n    # Process each block and each coordinate triplet\\n    for b in range\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n        for i in range\u001b[0m\u001b[32m(\u001b[0m\u001b[32mblock_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n            m = b * block_size + i\\n            if m >= M:\\n                break\\n            idx = m * 3\\n            # Load coordinates for the m-th triplet\\n            x = coord\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            y = coord\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx + 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            z = coord\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx + 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n            # Compute base index for sph_grad for this coordinate\\n            base = b * block_size * output_stride + i * output_stride + col_offset\\n            if base + 10 >= sph_grad.numel\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n                continue\\n            # Load spherical gradients g0 to g10\\n            g0  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g1  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g2  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g3  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g4  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g5  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g6  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g7  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g8  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g9  = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g10 = sph_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32mbase + 10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n            # Precompute polynomial terms\\n            VAR06 = x ** 4\\n            VAR07 = x ** 3\\n            VAR08 = x ** 2\\n            VAR15 = y ** 4\\n            VAR16 = y ** 3\\n            VAR17 = y ** 2\\n            VAR24 = z ** 4\\n            VAR25 = z ** 3\\n            VAR26 = z ** 2\\n\\n            # Load current gradients\\n            g_x = coord_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g_y = coord_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx + 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n            g_z = coord_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx + 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n            # Update gradients identically as in the Triton kernel\\n            g_x = g_x + \\\\\\n                  g0 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g1 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST038 * VAR08 * z - CONST052 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g10 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST029 * VAR07 * z + CONST043 * VAR25 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g2 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR08 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST059 * VAR17 + CONST064 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST006 * VAR06 - CONST045 * VAR17 * VAR26 + CONST063 * VAR24\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g3 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST041 * VAR08 * y * z - CONST049 * VAR16 * z + CONST057 * VAR25 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g4 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST000 * VAR24 + CONST001 * VAR08 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST002 * VAR26 + CONST055 * VAR17\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST007 * VAR06 + CONST010 * VAR15 + CONST056 * VAR17 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g5 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST048 * VAR16 * x + y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST019 * VAR07 + CONST019 * VAR26 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g6 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST005 * VAR25 * x + z * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST004 * VAR07 + CONST046 * VAR17 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g7 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST049 * VAR16 * x - CONST051 * VAR07 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g8 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST008 * VAR25 * x + z * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST039 * VAR17 * x - CONST054 * VAR07\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g9 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST024 * VAR07 + CONST038 * VAR26 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n            g_y = g_y + \\\\\\n                  g1 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST052 * VAR07 * z - CONST052 * VAR25 * x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g2 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST039 * VAR26 * x * y + CONST053 * VAR07 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g3 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST058 * VAR07 * z + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST034 * VAR17 * z + CONST057 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g4 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST047 * VAR07 * y + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST030 * VAR16 + CONST046 * VAR26 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g5 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR17 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST060 * VAR08 + CONST060 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST011 * VAR06 + CONST012 * VAR24 + CONST014 * VAR08 * VAR26 - CONST060 * VAR15\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g6 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST046 * VAR25 * y + z * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST031 * VAR16 + CONST046 * VAR08 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g7 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR17 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST057 * VAR08 - CONST057 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m - CONST061 * VAR06 + CONST061 * VAR24\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g8 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST021 * VAR25 * y + CONST039 * VAR08 * y * z\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g9 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST027 * VAR06 + CONST027 * VAR24 + CONST044 * VAR08 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n            g_z = g_z + \\\\\\n                  g0 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST029 * VAR25 * x + CONST043 * VAR07 * z\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g1 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST038 * VAR26 * x + CONST052 * VAR07\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g10 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST009 * VAR06 + CONST009 * VAR24 + CONST040 * VAR08 * VAR26\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g2 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST062 * VAR07 * z + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST039 * VAR17 * z + CONST054 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g3 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST058 * VAR07 * y + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST042 * VAR26 * y - CONST049 * VAR16\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g4 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST005 * VAR07 * z + x * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST046 * VAR17 * z + CONST050 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g5 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST048 * VAR16 * z + y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST019 * VAR08 * z + CONST020 * VAR25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g6 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR26 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST002 * VAR08 + CONST056 * VAR17\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST003 * VAR06 + CONST007 * VAR24 + CONST017 * VAR15 + CONST056 * VAR08 * VAR17\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g7 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32m-CONST049 * VAR16 * z + CONST051 * VAR25 * y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g8 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST001 * VAR26 * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST018 * VAR17 + CONST037 * VAR08\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + CONST036 * VAR24 + CONST045 * VAR08 * VAR17 - CONST063 * VAR06\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + \\\\\\n                  g9 * y * \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCONST024 * VAR25 + CONST038 * VAR08 * z\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n            # Store updated gradients\\n            coord_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = g_x\\n            coord_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx + 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = g_y\\n            coord_grad\u001b[0m\u001b[32m[\u001b[0m\u001b[32midx + 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = g_z\\n    return coord_grad\\n\\n\\n########################\\n\\ndef test_fifth_order_bwd\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    \"\"\"\\n    Run integrated tests for the PyTorch implementation.\\n    Returns a dictionary with outputs from each test case under key \\'pytorch\\'.\\n    \"\"\"\\n    results = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    # ---------------- Test Case 1 ----------------\\n    # Settings: M = 4 coordinate triplets, block_size = 2, output_stride = 11, col_offset = 0\\n    block_size = 2\\n    M = 4\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n    output_stride = 11\\n    col_offset = 0\\n\\n    coord = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3 * M, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_pytorch = coord.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_grad_pytorch = torch.zeros_like\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    sph_grad = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks * block_size * output_stride, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    updated_grad_pytorch = fifth_order_bwd_pytorch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_pytorch, coord_grad_pytorch.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, sph_grad,\\n                                                     block_size, col_offset, output_stride\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    results\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\'test_case_1\\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \\'pytorch\\': updated_grad_pytorch \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    # ---------------- Test Case 2 ----------------\\n    # Settings: M = 5 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mnot a multiple of block_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, block_size = 3, output_stride = 13, col_offset = 2\\n    block_size = 3\\n    M = 5\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n    output_stride = 13\\n    col_offset = 2\\n\\n    coord = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3 * M, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_pytorch = coord.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_grad_pytorch = torch.zeros_like\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    sph_grad = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks * block_size * output_stride, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    updated_grad_pytorch = fifth_order_bwd_pytorch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_pytorch, coord_grad_pytorch.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, sph_grad,\\n                                                     block_size, col_offset, output_stride\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    results\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\'test_case_2\\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \\'pytorch\\': updated_grad_pytorch \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    # ---------------- Test Case 3 ----------------\\n    # Settings: Larger tensor, M = 16, block_size = 4, output_stride = 15, col_offset = 1\\n    block_size = 4\\n    M = 16\\n    num_blocks = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM + block_size - 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m // block_size\\n    output_stride = 15\\n    col_offset = 1\\n\\n    coord = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3 * M, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_pytorch = coord.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_grad_pytorch = torch.zeros_like\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    sph_grad = torch.randn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnum_blocks * block_size * output_stride, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDEVICE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n    updated_grad_pytorch = fifth_order_bwd_pytorch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_pytorch, coord_grad_pytorch.clone\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, sph_grad,\\n                                                     block_size, col_offset, output_stride\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    results\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\'test_case_3\\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \\'pytorch\\': updated_grad_pytorch \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n    return results\\n\\n# Execute tests \u001b[0m\u001b[32m(\u001b[0m\u001b[32monly one print statement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\ntest_results = test_fifth_order_bwd\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtest_results\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'pytorch_runs'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'pytorch_output'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'stderr'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'Traceback \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmost recent call last\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 35, in wrapper\\n    return fn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m*args, **kwargs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 1187, in arange\\n    return semantic.arange\u001b[0m\u001b[32m(\u001b[0m\u001b[32mstart, end, _builder\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/semantic.py\", line 613, in arange\\n    raise ValueError\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"arange\\'s range must be a power of 2\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nValueError: arange\\'s range must be a power of 2\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmost recent call last\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 228, in <module>\\n    test_results = test_fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 203, in test_fifth_order_bwd_triton\\n    fifth_order_bwd_triton\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_triton, coord_grad_triton, sph_grad,\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 330, in <lambda>\\n    return lambda *args, **kwargs: self.run\u001b[0m\u001b[32m(\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m=\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m, \u001b[0m\u001b[32mwarmup\u001b[0m\u001b[32m=\u001b[0m\u001b[32mFalse\u001b[0m\u001b[32m, *args, **kwargs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 623, in run\\n    kernel = self.compile\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n             ^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 273, in compile\\n    module = src.make_ir\u001b[0m\u001b[32m(\u001b[0m\u001b[32moptions, codegen_fns, module_map, context\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 100, in make_ir\\n    return ast_to_ttir\u001b[0m\u001b[32m(\u001b[0m\u001b[32mself.fn, self, \u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m, \u001b[0m\u001b[32moptions\u001b[0m\u001b[32m=\u001b[0m\u001b[32moptions\u001b[0m\u001b[32m, \u001b[0m\u001b[32mcodegen_fns\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcodegen_fns\u001b[0m\u001b[32m,\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\ntriton.compiler.errors.CompilationError: at 12:21:\\ndef fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_ptr, coord_grad_ptr, sph_grad_ptr,\\n                           block_size: tl.constexpr, coord_numel: tl.constexpr,\\n                           output_numel: tl.constexpr, col_offset: tl.constexpr,\\n                           output_stride: tl.constexpr\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    \"\"\"\\n    Triton kernel for the backward pass.\\n    It loads coordinate values and corresponding spherical gradients \u001b[0m\u001b[32m(\u001b[0m\u001b[32mg0 to g10\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and updates the gradient buffer.\\n    \"\"\"\\n    # Each program handles one block \u001b[0m\u001b[32m(\u001b[0m\u001b[32mgrid dimension 0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    block_id = tl.program_id\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_stride = 3\\n    coord_striding = tl.arange\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0, block_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m * coord_stride\\n                     ^\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'stdout'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m''\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'triton_runs'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'triton_output'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'stderr'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'Traceback \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmost recent call last\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 35, in wrapper\\n    return fn\u001b[0m\u001b[32m(\u001b[0m\u001b[32m*args, **kwargs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/core.py\", line 1187, in arange\\n    return semantic.arange\u001b[0m\u001b[32m(\u001b[0m\u001b[32mstart, end, _builder\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/language/semantic.py\", line 613, in arange\\n    raise ValueError\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"arange\\'s range must be a power of 2\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nValueError: arange\\'s range must be a power of 2\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmost recent call last\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 228, in <module>\\n    test_results = test_fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/temp_files/test.py\", line 203, in test_fifth_order_bwd_triton\\n    fifth_order_bwd_triton\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_triton, coord_grad_triton, sph_grad,\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 330, in <lambda\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n    return lambda *args, **kwargs: self.run\u001b[0m\u001b[32m(\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m=\u001b[0m\u001b[32mgrid\u001b[0m\u001b[32m, \u001b[0m\u001b[32mwarmup\u001b[0m\u001b[32m=\u001b[0m\u001b[32mFalse\u001b[0m\u001b[32m, *args, **kwargs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/runtime/jit.py\", line 623, in run\\n    kernel = self.compile\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n             ^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 273, in compile\\n    module = src.make_ir\u001b[0m\u001b[32m(\u001b[0m\u001b[32moptions, codegen_fns, module_map, context\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/triton_eval/.venv/lib/python3.12/site-packages/triton/compiler/compiler.py\", line 100, in make_ir\\n    return ast_to_ttir\u001b[0m\u001b[32m(\u001b[0m\u001b[32mself.fn, self, \u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m, \u001b[0m\u001b[32moptions\u001b[0m\u001b[32m=\u001b[0m\u001b[32moptions\u001b[0m\u001b[32m, \u001b[0m\u001b[32mcodegen_fns\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcodegen_fns\u001b[0m\u001b[32m,\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\ntriton.compiler.errors.CompilationError: at 12:21:\\ndef fifth_order_bwd_triton\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcoord_ptr, coord_grad_ptr, sph_grad_ptr,\\n                           block_size: tl.constexpr, coord_numel: tl.constexpr,\\n                           output_numel: tl.constexpr, col_offset: tl.constexpr,\\n                           output_stride: tl.constexpr\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    \"\"\"\\n    Triton kernel for the backward pass.\\n    It loads coordinate values and corresponding spherical gradients \u001b[0m\u001b[32m(\u001b[0m\u001b[32mg0 to g10\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and updates the gradient buffer.\\n    \"\"\"\\n    # Each program handles one block \u001b[0m\u001b[32m(\u001b[0m\u001b[32mgrid dimension 0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    block_id = tl.program_id\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    coord_stride = 3\\n    coord_striding = tl.arange\u001b[0m\u001b[32m(\u001b[0m\u001b[32m0, block_size\u001b[0m\u001b[32m)\u001b[0m\u001b[32m * coord_stride\\n                     ^\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'stdout'\u001b[0m: \u001b[32m''\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'outputs_match'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(sample_ds[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
